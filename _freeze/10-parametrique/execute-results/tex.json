{
  "hash": "a9f3f161b167bfd543bf5facb9343c80",
  "result": {
    "markdown": "# **Modèles paramétriques**\n\n\n**Objectifs**: présenter, assez rapidement, la logique des modèles de type **AFT** (**Accelerated Failure Time**), principalement celui de *Weibull*. \n\n## Principes\n\n* Dans les modèles paramétriques usuels, la durée de survie est distribuée selon une loi dont la densité $f(t)$ pleinement paramétrée.  \n* Pour utiliser l’approche paramétrique, il faut avoir de bonnes raisons de penser que durée de survie sont distribués selon une certaine loi connue plutôt qu’une autre. \n* La majorité des distributions reposent sur une hypothèse dite AFT (**Acceleretad Failure Time**). Une autre, *Gompertz*, très utilisée en démographie (mortalité), repose seulement sur la proportionnalité des risques. Certaines peuvent reposer sur les deux comme le modèle de *Weibull*. Enfin, les modèles *log-logistique* ou *log-normal* n'ont qu'une paramétrisation de type *AFT*.\n\n## Hypothèse AFT: Accelerated Failure Time\nL’hypothèse **AFT** signifie que l’effet des covariables est multiplicatif par rapport à la durée de survie/séjour.\nPar opposition, les modèles PH décrivent un effet multiplicatif par rapport au risque.\n\nSelon les caractérisques des individus, le temps *ne s'écoulent pas à la même vitesse*, ils ne partagent donc plus la même métrique temporelle. Cela renvoie a des interprétations de type *dilation/contraction* du temps, par analogie à la théorie de la relativité.  \n\nExemple simple: la durée de vie d'un être humain et d'un chien.  \nOn dit qu'une année de vie d'un être humain est équivalent à 7 années de vie d'un chien. C'est typiquement une hypothèse d'AFT.  \n$S_h(t) = S_c(7\\times t)$. \n\nC'est ce facteur multiplicatif qu'estime un modèle paramétrique de type AFT.\n\n$$S(t_i | X_1)=  S(\\phi t_i | X_0)$$\n\nRemarque: si un modèle s'estime AFT s'estime également sous hypothèse PH comme celui de Weibull: $h(t_i | X_1)= -\\rho \\phi h(t_i | X_0)$\n\n* Avantage: l'interprétation des modèles est directement liée aux fonctions de survie. Cela s'avère donc pratique après une analyse non paramétrique de type Kaplan-Meier par exemple.\n* Inconvénient: ne permet pas l'introduction de variables dynamiques.  \n\n*Humain versus chien*: la probabilité qu'un être humain survive 80 ans est égale à la probabilité qu'un chien survive 11 ans (80/7). Le temps s'écoulerait donc plus vite pour le chien que pour l'être humain du point de vue d'un référentiel extérieur. Ce raisonnement peut s'appliquer aux quantile du temps de survie: le temps de survie médian d'un être humain est 7 fois plus élevé que celui d'un chien. En terme d’interprétation des paramètres estimés, si la durée de survie est plus courte, alors le risque est plus élevé.\n \n\n## Principe de construction des modèles AFT \n\nLe raisonnement mathématique est ici  plus complexe que pour les modèles de Cox ou à durée discrète. On donnera juste quelques pistes en début de raisonnement.\nOn part d'une expression proche du modèle linéaire à une transformation logarithmique près de la variable dépendante. En imposant la contrainte $t_i>0$, en ne posant qu'une seule covariable $X$ de type binaire, et en se situant de nouveau dans une logique de temps continu (pas d'évènement simultané):\n\n$$log(t_i)= \\alpha_0 +  \\alpha_1X_i + bu_i$$\n\n$b$ est un paramètre d'échelle identique pour toutes les observations et $u_i$ un terme terme d'erreur qui suit une loi de distribution de densité $f(u)$. Cette combinaison linéaire définira le paramètre de position.  C'est la forme de $f(u)$ qui définie le type de modèle paramétrique.     \n\nOn peut écrire: $f(u_i) = f(\\frac{log(t_i)- \\alpha_0 -  \\alpha_1X_i}{b})$. \n\nRemarque: pour une distibution normale/gaussienne, le paramètre de position est l'espérance et le paramètre d'échelle l'écart-type. \n\n\n## Quelques modèles paramétriques usuels\n\n**Modèle exponentiel et de Weibull**    \n\n**Weibull**\n\n* Peut estimer un modèle PH ou AFT, d'où sa popularité.\n* Distribution monotone des durées d'évènement, toujours croissante ou décroissante.\n* $f(t)=\\lambda\\alpha t^{\\alpha - 1}e^{-\\alpha t^\\lambda}$ et  $h(t)=\\lambda\\alpha(\\lambda t)^{\\alpha - 1}$, $\\alpha>0$ et $\\lambda>0$. Si $\\lambda>1$ le risque est croissant, décroissant si $\\lambda<1$, et est constant (loi exponentielle) si $\\lambda=1$.  \n\n*Exponentiel*  \n\n* Processus sans mémoire,  utilisé pour étudier par exemple la durée de vie composants électriques ou électroniques. \n* La fonction de risque est une constante. \n* Cas limite de la loi de Weibull. Un modèle de type exponentiel peut-être de type AFT ou PH.\n* Pour contourner la constance du risque dans le temps, on peut estimer un modèle en scindant la durée en plusieurs intervalles. Le risque sera constant à l'intérieur de ces intervalles, il s'agit d'un modèle \"exponential piecewise\" (exponentiel par morceau).   \n\n\n**Log-logistique**\n\n* Estime un modèle de type AFT seulement. Proche du modèle log-normal (plus difficile à estimer).\n* Permet une interprétation en terme d'Odds de survie.\n* La fontion du risque peut-être \"U-shaped\" (unimodale croissante puis décroissante).  \n\n\n**Autres lois**: Gompertz (PH seulement), Gamma et Gamma généralisé.....\n\n\n**Sélection de la loi**\nOn peut sélectionner la loi en comprarant les AIC où les BIC des modèles. Pour le modèle de Weibull, on peut regarder s'il ajuste bien les données si la transformation $log(-log(S(t_i)))$ est linéaire par rapport à $log(t_i)$.\n\n***Application***\n\n***Comparaison des AIC (sans covariable)***    \n\n* Weibull:   400.1  \n* Exponentiel: 461.0  \n* Gompertz:  409.6  \n* Log-logistique: 391.8*\n\n\n## Exemple avec le modèle de Weibull\n\n\n**AFT**\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n```\n<IPython.core.display.HTML object>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n        Failure _d: died\n  Analysis time _t: stime\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n          _t | Time ratio   Std. err.      z    P>|z|     [95% conf. interval]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n-------------+----------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n        year |\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n      1.176      0.143     1.33   0.184        0.926       1.493\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n         age |      0.940      0.023    -2.49   0.013        0.896       0.987\n     surgery |      7.173      5.591     2.53   0.011        1.557      33.048\n       _cons |      0.049      0.425    -0.35   0.729        0.000    1.31e+06\n-------------+----------------------------------------------------------------\n       /ln_p |     -0.587      0.093    -6.33   0.000       -0.769      -0.405\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n-------------+----------------------------------------------------------------\n           p |\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n      0.556      0.052                         0.464       0.667\n         1/p |      1.798      0.167                         1.499       2.157\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNote: _cons estimates baseline time.\n```\n:::\n:::\n\n\nUn jour de survie d’une personne qui n’a pas été opérée d’un pontage correspond environ à 7 jours de survie d’une personne opérée. Cette remise à l’échelle de la métrique temporelle entre les deux groupes exprime bien le gain en durée de survie pour les personnes opérées, soit des risques journaliers de décès plus faibles (et plus faibles à valeurs constantes, proportionnalité oblige).\n\n\n**PH**\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-stdout}\n```\n\n        Failure _d: died\n  Analysis time _t: stime\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n------------------------------------------------------------------------------\n          _t | Haz. ratio   Std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        year |      0.914      0.061    -1.36   0.175        0.802       1.041\n         age |      1.035      0.014     2.47   0.014        1.007       1.063\n     surgery |      0.334      0.145    -2.52   0.012        0.143       0.783\n       _cons |      5.368     25.895     0.35   0.728        0.000   68506.303\n-------------+----------------------------------------------------------------\n       /ln_p |     -0.587      0.093    -6.33   0.000       -0.769      -0.405\n-------------+----------------------------------------------------------------\n           p |      0.556      0.052                         0.464       0.667\n         1/p |      1.798      0.167                         1.499       2.157\n------------------------------------------------------------------------------\nNote: _cons estimates baseline hazard.\n```\n:::\n:::\n\n\nRemarque: Si on avait reporté les coefficients (échelle log) $b_{ph} = -\\rho \\times b_{aft}$. Ici $-0.556 \\times (1.97) = -1.096$. Et $e^{-1.096}=0.334$\n\n\nAttention: on ne peut pas comparer la qualité d'un modèle paramétrique à celle d'un modèle de Cox par des critères type AIC ou BIC. Les deux méthodes d'estimation diffèrent.\n\n\n## Le modèle de Parmar-Royston\n\n* Le bon ajustement par une loi de distribution predéfinie peut s'avérer contraignante. Le modèle de Cox avait justement pour objectif de se défaire de cette contrainte, la plupart des distributions utilisée étant monotone ou unimodale (log-logistique ou log-normal). \n* Le principe des splines peut-être rapproché de celui qui a été utilisé plus haut dans le modèle logistique à durée discrète avec l'introduction des polynomes [ $f(t)= (a_1\\times t) + (a_2\\times t^2) + (a_3\\times t^3) + ...+ (a_k\\times t^k)$. \n  * Cette méthode brute d'ajustement consiste finalement à introduire une intéraction ou plusieurs intéractions entre la variable de durée avec elle-même.\n  * Elle est sujette à une forte sensibilité aux outliers (overfitting) au delà de $k>2$ [lors la formation il suffit de la tester pour k=3 et calculer la probabilité conditionnelle pour s'en convaincre].\n* Les **splines cubiques restreintes** propose une méthode d'ajustement et de lissage de meilleure qualité et permet de contrôler les effets overfitting.\n  * les splines cubiques sont donc basées sur des polynomes d'ordre 3 (d'où cubique) mais estimé par morceau (intervalles). les morceaux sont définis manuellement ou par un nombre de degrés de liberté obtenu par quantile du logarithme de la fonction de survie après avoir exclu les observation censurées. \n    * Deux degrés de liberté (1 noeud) avec un intervalle allant jusqu'au log de la moitié des survivants et un second à partir de cette seconde moitié.\n    * Sur le même principe trois degrés de liberté (2 noeuds) coupe la durée en 3 intervalles sur ses terciles.\n    * En pratique, il est préférable de donner à l'application de nombre de degré de liberté plutôt que d'indiquer manuellement la position des noeuds. \n    * Il convient également de ne pas être trop gourmand sur le nombre de noeuds, un ou deux étant souvant suffisant (donc 2 ou 3 degrés de liberté).\n    * On peut choisir le nombre de degrés de liberté en estimant des modèles sans covariables et comparer les AIC (vraisemblance pénalisée).\n* Contrairement aux autres modèles, et sans rentrer dans les détails, le modèle de Parmar-Royston part de la fonction de risque cumulée et non des taux de risque/hasard. Les risk ratios sont obtenus en utilisant les relations entre les différentes grandeurs (voir section *théorie).\n\n    \n**Exemple**  \n\nAvec 2 degrés de liberté (un noeud): \n\n::: {.cell execution_count=3}\n\n::: {.cell-output .cell-output-stdout}\n```\n\nLog likelihood = -183.14497                                Number of obs = 103\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n------------------------------------------------------------------------------\n             |     exp(b)   Std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n        year |      0.885      0.059    -1.83   0.067        0.777       1.008\n         age |      1.030      0.014     2.23   0.026        1.004       1.058\n     surgery |      0.373      0.162    -2.26   0.024        0.159       0.876\n       _rcs1 |      3.157      0.374     9.72   0.000        2.503       3.981\n       _rcs2 |      1.289      0.105     3.12   0.002        1.099       1.511\n       _cons |    729.507   3487.989     1.38   0.168        0.062    8.57e+06\n------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation.\n```\n:::\n:::\n\n\nA savoir: \n\n- Avec un degré de liberté, le modèle de Parmar-Royston estime un modèle de Weibull sous paramétrisation PH.\n- Les paramètres pour les splines sont difficilement interprétables voire impossibles à interpréter directement. Elles servent calculer la baseline du risque via l'équation du polynome (non reporté car expression bien corsée). \n\n",
    "supporting": [
      "10-parametrique_files\\figure-pdf"
    ],
    "filters": []
  }
}