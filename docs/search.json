[
  {
    "objectID": "index.html#le-support",
    "href": "index.html#le-support",
    "title": "Introduction à l’analyse des durées",
    "section": "Le support",
    "text": "Le support\nMISE A JOUR DU SUPPORT EN COURS\n\nL’ensemble des sections devraient être disponible la semaine du 07 Aout 2022\nLe support est maintenant intégralement disponible en format pdf en cliquant sur l’icône au dessus de la barre de recherche.\nQuelques mises à jour de contenu seront réalisées d’ici la fin septembre:"
  },
  {
    "objectID": "index.html#bibliographie-vf",
    "href": "index.html#bibliographie-vf",
    "title": "Introduction à l’analyse des durées",
    "section": "Bibliographie vf",
    "text": "Bibliographie vf\nLes éléments bibliographiques qui figurent ci-dessous proviennent du champ des sciences sociales. Elle est courte, mais efficace. Quelle que soit la langue, le nombre de cours ou support sont très nombreux en médecine, qui est ici l’espace privilégié de l’ingénierie méthodologique. On trouve également de (trop) nombreux tutoriels à dominante mise en pratique avec R.\nAccès en ligne\n\nCours Gilbert Colletaz (Université d’Orléans - master d’économétrie).\n\nLe cours est mis à jour tous les ans, applications uniquement avec Sas.\nDernière version 2020: lien\n\nDocument de travail de Simon Quantin (Insee).\n\nCouvre l’ensemble des techniques de base d’analyse des durées en durée dite continue. Il propose surement la meilleure introduction en langue française à la problématique de la fragilité.\nApplication en R seulement (attention au passage de la v3 du package survival)\n2019 - pas de mise à jour: lien\n\n\nOuvrage de référence en démographie:\nL’analyse démographique des biographies de Daniel Courgeau et Eva Lelièvre (Edition de l’Ined - 1989)."
  },
  {
    "objectID": "index.html#outils",
    "href": "index.html#outils",
    "title": "Introduction à l’analyse des durées",
    "section": "Outils",
    "text": "Outils\n\nSupport réalisé sous Rstudio avec le système de publication Quarto\nLangages utilisés pour la partie programmation:\n\nR\nStata v18\nSas\nPython"
  },
  {
    "objectID": "01-presentation.html#questions",
    "href": "01-presentation.html#questions",
    "title": "1  L’analyse des durées",
    "section": "1.1 Questions",
    "text": "1.1 Questions\nOn dispose de données dites “longitudinales”, et on cherche à appréhender l’occurence d’un évènement au sein d’une population. Les problématiques se basent sur les questions suivantes:\n\n\nObserve-t-on la survenue de l’évènement pour l’ensemble des individus?\nQuelle est la durée jusqu’à la survenue de l’évènement?\nQuels sont les facteurs qui favorisent la survenue de cet évènement? Facteurs fixes ou facteurs pouvant apparaitre/changer au cours de la période d’observation: variables dynamiques (TVC: Time Varying Covariate)"
  },
  {
    "objectID": "01-presentation.html#terminologies",
    "href": "01-presentation.html#terminologies",
    "title": "1  L’analyse des durées",
    "section": "1.2 Terminologies",
    "text": "1.2 Terminologies\n\n\n\n\n\n\n\nFrançais\nAnglais\n\n\n\n\nModèles de durée\nDuration analysis (Econométrie)\n\n\nAnalyse de survie\nSurvival analysis (Epidémiologie, médecine, démographie)\n\n\nAnalyse de fiabilité\nFailure time data analysis (Statistiques industrielles)\n\n\nAnalyse des transitions\nEvent-history analysis (Démographie, Sociologie)\n\n\nDonnées de séjour\nTransition analysis (Sociologie)\n\n\nHistoires de vie"
  },
  {
    "objectID": "01-presentation.html#exemples-danalyse",
    "href": "01-presentation.html#exemples-danalyse",
    "title": "1  L’analyse des durées",
    "section": "1.3 Exemples d’analyse",
    "text": "1.3 Exemples d’analyse\n\nNuptialité, Mise en couple: cohabiter, décohabiter, se marier, Rompre une union …\n\nLogement: Changement de statut (locataire &lt;=&gt; propriétaire), mobilité résidentielle …\n\nEmploi: Trouver un 1er emploi, changer d’emploi, entrée ou sortie du chômage …\n\nFécondité: Avoir un premier enfant, avoir un nouvel enfant …\n\nMortalité: Décéder après diagnostic, survivre après l’administration un traitement…"
  },
  {
    "objectID": "01-presentation.html#elements-nécessaire-à-lanalyse",
    "href": "01-presentation.html#elements-nécessaire-à-lanalyse",
    "title": "1  L’analyse des durées",
    "section": "1.4 Elements nécessaire à l’analyse",
    "text": "1.4 Elements nécessaire à l’analyse\n\nUn processus temporel\n\nUne échelle de mesure ou métrique temprelle: minutes, heures, jours, mois, années….\nUne origine définissant un évènement de départ.\n\nUne définition précise de l’évènement d’étude.\n\nUne durée entre le début et la fin de la période d’observation, si nécessaire avec la fin de la période d’exposition au risque.\n\nUne population soumise au risque de connaître l’évènement (Risk Set)\nDes variables explicatives ou covariables\n\nFixes: genre, génération, niveau de diplôme, csp,……\nDynamiques (TVC: Time varying covariates): Mesurées à tout moment entre le début et la sortie de l’observation: statut matrimonial, taille du ménage, statut d’activité…"
  },
  {
    "objectID": "02-donnees.html#données-prospectives-et-rétrospectives",
    "href": "02-donnees.html#données-prospectives-et-rétrospectives",
    "title": "2  Les Données",
    "section": "2.1 Données prospectives et rétrospectives",
    "text": "2.1 Données prospectives et rétrospectives\n\n2.1.1 Les données prospectives\n\nIndividus suivis à des dates successives.\nInstrument de mesure identique à chaque vague (si possible).\nAvantages: qualité des données (moins de biais de mémoire).\n\nInconvénients: délais pour les exploiter dans une analyse, mêmes hypothèses entre deux passages pas forcément respectées, attrition, problèmes liés aux âges d’inclusion.\n\nA noter l’exploitation croissante des données administratives qui peuvent regorger d’informations biographiques. Déjà disponibles, le problème du coût de collecte est contourné. Ce type de données comprend par exemple les informations issues des fichiers des Ressources Humaines des entreprises, qui sont par exemples actuellement exploitées à l’Ined, par exemple dans le cadre du projet « worklife » (https://worklife.site.ined.fr/). Elles engendrent en revanche des questionnements techniques liésà l’inférence ((on ne travaille directement pas sur des échantillons).\n\n\n2.1.2 Les données rétrospectives\n\nIndividus interrogés une seule fois.\nRecueil de biographies thématiques depuis une origine jusqu’au moment de l’enquête.\nRecueil d’informations complémentaires à la date de l’enquête (âge, sexe, csp au moment de l’enquête et/ou csp représentative).\nAvantages: Information longitudinale immédiatement disponible.\nInconvénients: questionnaire long, informations datées qui font appel à la mémoire de l’enquêté.e. A de rares exceptions (enfant, mariage), il est difficile d’aller chercher des datations trop fines avec une retrospectivité assez longue.\n\nLes deux types de recueil peuvent être mixés avec des enquêtes à passages répétés (prospectifs) comprenant des informations retrospectives entre 2 vagues (Exemple: la cohorte Elfe de l’Ined-Inserm ou la Millenium-Cohort-Study en Grande Bretagne)."
  },
  {
    "objectID": "02-donnees.html#grille-ageven",
    "href": "02-donnees.html#grille-ageven",
    "title": "2  Les Données",
    "section": "2.2 Grille AGEVEN",
    "text": "2.2 Grille AGEVEN\nPour recueillir des informations biographiques retrospectives, on utilise généralement la méthode des grilles AGEVEN.\nIl s’agit d’une grille âge-évènement, de type chronologique, avec des repères temporels en ligne (âge, année). En colonne, sont complétés de manière progressive et relative, les évènements relatifs à des domaines, par exemple la biographie professionnelle, familiale, résidentielle…\n\n\n\n\n\n\nRéférences\n\n\n\n\nAntoine P., X. Bry and P.D. Diouf, 1987 “La fiche Ageven : un outil pour la collecte des données rétrospectives”, Statistiques Canada 13(2).\nVivier G, “Comment collecter des biographies ? De la fiche Ageven aux grilles biographiques, Principes de collecte et Innovations récentes”, Acte des colloques de l’AIDELF, 2006.\nGRAB, 1999, “Biographies d’enquêtes : bilan de 14 collectes biographiques”, Paris, INED.\n\nExemple grille Ageven page 121: &lt;http://retro.erudit.org/livre/aidelf/2006/001404co.pdf&lt;"
  },
  {
    "objectID": "02-donnees.html#enregistrement-des-données",
    "href": "02-donnees.html#enregistrement-des-données",
    "title": "2  Les Données",
    "section": "2.3 Enregistrement des données",
    "text": "2.3 Enregistrement des données\nLa question du format des fichiers biographiques mis à disposition n’est pas neutre, en particulier au niveau des manipulations pour créer le fichier d’analyse, opération qui pourra s’avérer particulièrement chronophage et complexe si plusieurs modules doivent être appariés. On distingue trois formats d’enregistrement.\n\n2.3.1 Large [format individu]\nUne ligne par individu, qui renseigne sur une même ligne tous les évènements liés à un domaine : les datations et les caractéristiques des évènements.\nExemple: domaine : unions - échelle temporelle: année - fin de l’observation en 1986:\n\n\n\nid\ndebut1\nfin1\ncause1\ndébut2\nfin2\ncause2\n\n\n\n\nA\n1979\n1982\ndécès conjoint\n1985\n.\n.\n\n\nB\n1983\n1984\nSéparation\n.\n.\n.\n\n\n\nInconvénients: peut générer beaucoup de vecteurs colonnes avec de nombreuses valeurs manquantes. Le nombre de colonnes va dépendre du nombre maximum d’évènements. Si ce nombre concerne un seul individu, on va multiplier le nombre de colonnes pour un niveau d’information très limité. Situation classique, le nombre d’enfants, où les naissances de rang élevé deviennent de plus en plus rares.\n\n\n2.3.2 Semi-long [format individu-évènements]\nC’est le format le plus courant de mise à disposition des enquêtes biographiques. Si les transitions sont de type continu, par exemple le lieu de résidence (on habite toujours quelque part), la date de fin de la séquence correspond à la date de début de la séquence suivante. Les dates de fin ne sont pas forcément renseignées sur une ligne pour des trajectoires continues, l’information peut être donnée sur la ligne suivante avec la date de début.\nPour la séquence qui se déroule au moment de l’enquête, la date de fin est souvent une valeur manquante, une fin de séquence pouvant se produire juste avant l’enquête au cours d’une même année. Il est également possible d’avoir une information qui ne s’est pas encore produite au moment de l’enquête, mais qui aura lieu peu de temps après (personne enceinte, donc une naissance probable la même année).\nExemple précédent (trajectoires discontinues):\n\n\n\nid\ndebut\nfin\ncause\nNumero séquence\n\n\n\n\nA\n1979\n1982\ndécès conjoint\n1\n\n\nA\n1985\n.\n.\n2\n\n\nB\n1983\n1984\nSéparation\n1\n\n\n\n\n\n2.3.3 Long [format individu-périodes]\nTypique des recueils prospectifs. Ils engendrent des lignes sans information supplémentaire par rapport à la ligne précédente.\nExemple précédent:\n\n\n\nid\nAnnée\ncause\nNumero séquence\n\n\n\n\nA\n1979\n.\n1\n\n\nA\n1980\n.\n1\n\n\nA\n1981\n.\n1\n\n\nA\n1982\nDécès conjoint\n1\n\n\nA\n1985\n.\n2\n\n\nA\n1986\n.\n2\n\n\nB\n1983\n.\n1\n\n\nB\n1984\nSéparation\n1\n\n\n\nIci les trajectoires ne sont pas continues. Une forme continue présenterait toute la trajectoire, avec l’ajout d’un statut du type être en couple ou non. Pour ID=A, en 1983 et 1984, deux lignes « pas couple » (cohabitant ou non) pourraient être insérées avec au total 3 séquences.\n Remarque : pour certaines analyses (par exemple analyse en temps discret), on doit transformer passer d’un format large ou semi-long à un format long, sur les durées observées ou sur des intervalles de durées construits."
  },
  {
    "objectID": "02-donnees.html#exemples-de-mise-à-disposition",
    "href": "02-donnees.html#exemples-de-mise-à-disposition",
    "title": "2  Les Données",
    "section": "2.4 Exemples de mise à disposition",
    "text": "2.4 Exemples de mise à disposition\nDeux enquêtes biographiques de type rétrospectives produite par l’Ined, avec un fichier qui fournit des informations générales sur les individus (une ligne par individu), et une série de modules biographiques en format individus-évènements.\n\n2.4.1 Enquête biographie et entourage (Ined)\nhttps://grab.site.ined.fr/fr/enquetes/france/biographie_entourage/\n\n\n\nBiographie et entourage: base caractéristiques individuelle\n\n\n\n\n\nBiographie et entourage: base biographique logements\n\n\n\n\n2.4.2 Enquête MAFE (Ined)\n\n\n\nMAFE: base caractéristiques individuelles\n\n\n\n\n\nMAFE: base biographique logement"
  },
  {
    "objectID": "03-theorie.html#temps-et-durée",
    "href": "03-theorie.html#temps-et-durée",
    "title": "3  La théorie",
    "section": "3.1 Temps et durée",
    "text": "3.1 Temps et durée\nLe temps est une dimension (la quatrième), la durée est sa mesure. La durée est tout simplement calculée par la différence, pour une échelle temporelle donnée, entre la fin et le début d’une période d’exposition ou d’observation.\nOn distingue généralement deux types de mesure de la durée : continue et discrète/groupée. Ces deux notions ne possèdent pas réellement de définition, la différence s’explique plutôt par la présence ou non de simultanéité dans l’occurrence des évènements. Le temps étant intrasèquement continu car deux évènements ne peuvent pas avoir lieu en « même temps ». C’est donc l’échelle temporelle choisie ou imposée par l’analyse et les données qui pourra rendre cette mesure continue ou discrète/groupée. Pour un physicien travaillant sur la théorie de la relativité avec des horloges atomiques, une minute (voire une seconde) est une mesure très groupée pour ne pas dire grossière du temps, alors que pour un géologue c’est une mesure continue. Pour ces deux disciplines, cette échelle de mesure n’est pas adaptée à leur domaine. Le choix de l’échelle temporelle doit être pertinent par rapport aux objectifs de l’analyse même si on dispose des informations très fines (dates de naissance exactes). Etudier la fécondité avec une métrique journalière n’aurait pas de sens.\nIl existe des situations où les durées sont par nature discrète, lorsqu’un évènement ne peut avoir lieu qu’à un moment précis (date d’anniversaire des contrats pour l’analyse des résiliation). Généralement dans les sciences sociales avec un recueil de données de type rétrospectif, les mesures dites discrètes sont plutôt de nature groupées. Pour une même année, on considèrera indifféremment des évènements qui se produiront un premier janvier et un 31 décembre d’une même année.\n\n\n\n\n\n\nImportant\n\n\n\n\nDurée continue : absence (ou très peu) d’évènements simultanés\n\nDurée discrète/groupée : présence d’évènements simultanés (en grand nombre)"
  },
  {
    "objectID": "03-theorie.html#le-risk-set",
    "href": "03-theorie.html#le-risk-set",
    "title": "3  La théorie",
    "section": "3.2 Le Risk Set",
    "text": "3.2 Le Risk Set\n\nIl s’agit de la population “soumise” ou “exposée” au risque lorsque \\(T=t_i\\). \nCette population varie dans le temps car:\n\nCertaines personnes ont connu l’évènement, donc ne peuvent plus être soumises au risque (ex: décès si on analyse la mortalité).\nCertaines personnes sortent de l’observation sans avoir (encore) observé l’évènement: décès si on analyse un autre type d’évènement, perdu.e.s de vue, fin de l’observation dans un recueil rétrospectif."
  },
  {
    "objectID": "03-theorie.html#la-censure",
    "href": "03-theorie.html#la-censure",
    "title": "3  La théorie",
    "section": "3.3 La Censure",
    "text": "3.3 La Censure\n\n\n\n\n\n\nImportant\n\n\n\nUne observation est dite censurée lorsque la durée d’observation est inférieure à la durée d’exposition au risque\n\n\n\n3.3.1 Censure à droite\nDéfinition\nCertains individus n’auront pas (encore) connu l’évènement à la date de l’enquête après une certaine durée d’exposition. On a donc besoin d’un marqueur permettant de déterminer que les individus n’ont pas observé l’évènement sur la période d’étude.\nPourquoi une information est-elle censurée (à droite)?\n\nFin de l’étude, date de l’enquête.\nPerdu de vue, décès si autre évènement étudié.\n\nEn pratique (important)\n\nNe pas exclure ces observations, sinon on surestime la survenue de l’évènement.\nNe pas les considérer a-priori comme sorties de l’exposition sans avoir connu l’évènement. Elles peuvent connaître l’évènement après la date de l’enquête ou en étant perdues de vue. Sinon on sous-estime la durée moyenne de survenue de l’évènement.\n\nExemple\nOn effectue une enquête auprès de femmes : On souhaite mesurer l’âge à la première naissance. Au moment de l’enquête, une femme est âgée de 29 ans n’a pas (encore) d’enfant.\nCette information sera dite «censurée».\nElle est clairement encore soumise au risque après la date de l’enquête. Au niveau de l’analyse, elle sera soumise au risque à partir de ses premières règles jusqu’au moment de l’enquête.\nHypothèse fondamentale\nLes observations censurées ont vis à vis du phénomène observé le même comportement que les observations non censurées. On dit que la censure est non informative. Elle ne dépend pas de l’évènement analysé. Normalement le problème ne se pose pas dans les recueil retrospectif. \nProblème posé par la censure informative\nPar exemple en analysant des décès avec un recueil prospectif, si un individu est perdu de vue en raison d’une dégradation de son état de santé, l’indépendance entre la cause de la censure et le décès ne peut plus être assurée.\nA l’Ined l’exploitation du registre des personnes atteintes de mucoviscidose (G.Bellis) donne une autre illustration de ce phénomène. Chaque année un nombre significatif de personnes sortent du registre (pas de résultats aux examens annuels). Si certain.e.s perdu.e.s de vue s’expliquent par des déménagements, émigration ou par un simple problème d’enregistrement des informations, on note qu’ils/elles sont nombreu.se.s à présenter une forme « légère » de la maladie. L’information pouvant être donnée ici par la mutation du gène. Comme il n’est pas recommandé de supprimer ou de traiter ces observations comme des censures à droite non informatives, on peut les appréhender comme un risque concurrent au décès ou à tout autre évènement analysé à partir de ce registre (voir section dédiée).\nLes graphiques suivant représentent, en temps calendaire et après sa transformation en durée, la logique des censures à droite. Le recueil des informations est ici de nature prospectives.\n\nTrait plein : durée observée\nPointillés : durée censurée\nBulle : moment de l’évènement\n\n\n\n\n\n\nSchéma évènement/censure en temps calendaire\n\n\n\n\n\nSchéma évènement/censure sous forme de durée\n\n\n\n\n\n\n3.3.2 Censure à gauche, troncature et censure par intervalle\nCensure à gauche\nL’évènement s’est produit avant le début période d’observation. Typique des données prospectives, de type registre, avec des âges d’inclusion différenciés.\nCensure par intervalle Un évènement peut se produire entre 2 temps d’observations sans qu’on puisse les observer (ex: en criminologie récidive d’un delit entre deux arrestations). Un phénomène de censure à droite avec perdu.e de vue peut se transformer en censure par intervalle lorsque la personne réapparait et est de nouveau incluse dans les données.\nTroncature\nPar l’exemple, on analyse la survie d’une population. Seule la survie des individus vivants à l’inclusion peut être analysée (troncature à gauche). On peut également trouver un phénomène de troncature lorsqu’on mesure la durée à partir ou jusqu’à un certain seuil niveau.\nCes situations sont généralement plutôt bien contrôlées dans les recueils rétrospectifs. Elles sont assez courantes lorsque le recueil est de type prospectif.\nDurée d’observation supérieure à la durée d’exposition\nA l’inverse des individus peuvent sortir de l’exposition avant la fin de la période d’observation, et il convient donc de corriger la durée de cette sortie.\nUn exemple simple : si au moment de l’enquête une femme sans enfant a 70 ans, cela n’a pas de sens de continuer de l’exposer au risque au-delà d’un certain âge. Si on ne dispose pas d’information sur l’âge à la ménopause on peut tronquer la durée un peu au-delà de l’âge le plus élevé à la première naissance observée dans les données."
  },
  {
    "objectID": "03-theorie.html#les-grandeurs",
    "href": "03-theorie.html#les-grandeurs",
    "title": "3  La théorie",
    "section": "3.4 Les grandeurs",
    "text": "3.4 Les grandeurs\n\n3.4.1 Les grandeurs utilisées\n\nLa fonction de survie: \\(S(t)\\)\nLa fonction de répartition: \\(F(t)\\)\nLa fonction de densité: \\(f(t)\\)\nLe risque instantané: \\(h(t)\\)\nLe risque instantané cumulé: \\(H(t)\\)\n\nRemarques:\n\nToutes ces grandeurs sont mathématiquement liées les unes par rapport aux autres. En connaître une permet d’obtenir les autres.\n\nAu niveau formel on se placera ici du point de vue où la durée mesurée est strictement continue. Cela se traduit, entre autre, par l’absence d’évènements dits “simultanés”.\nLes expressions qui vont suivre ne sont pas des estimateurs, mais des grandeurs dont on précisera les propriétés. Les techniques d’estimations devront respecter ces propriétés .\n\n\n\n\n3.4.2 La fonction de Survie \\(S(t)\\)\nDans ce type d’analyse, il est courant d’analyser la courbe dite de survie. Hors contexte de mortalité on peut préférer la notion de courbe de de séjour (Courgeau, Lelièvre).\nLa fonction de survie donne la proportion de la population qui n’a pas encore connue l’évènement après une certaine durée \\(t\\). Elle y a donc “survécu”.\nFormellement, la fonction de survie est la probabilité de survivre au-delà de \\(t\\), soit:\n\n\\[S(t) = P(T&gt;t)\\]\nPropriétés:\n\n\\(S(0)=1\\)\n\\(\\lim\\limits_{t\\to{\\propto}}S(t)=0\\)\n\nLa fonction de survie est donc strictement non croissante.\n\n\n3.4.3 La fonction de répartition \\(F(t)\\)\nC’est la probabilité de connaitre l’évènement jusqu’en \\(t\\), soit:\n\n\\[F(t)=P(T\\leq{t})\\]\nSoit: \\(F(t) = 1 - S(t)\\)\nLa fonction de survie et la fonction de répartition sont donc deux grandeurs strictement complémentaires et décrivent la même information.\nPropriétés:\n\n\\(F(0)=0\\)\n\\(\\lim\\limits_{t\\to{\\propto}}F(t)=1\\)\n\n\n\n3.4.4 La fonction de densité \\(f(t)\\)\n\nPour une valeur de \\(t\\) donnée, la fonction de densité de l’évènement donne la distribution des moments où les évènement ont eu lieu. Elle est donnée dans un premier temps par la probabilité de connaitre l’évènement dans un petit intervalle de temps \\(dt\\). Si \\(dt\\) est proche de 0 (temps continu) alors cette probabilité tend également vers 0. On norme donc cette probabilité par \\(dt\\). Rappel: on est toujours ici dans la théorie.\n\nEn temps continu, la fonction de densité est donnée par la dérivée de la fonction de répartition: \\(f(t)=F'(t)=-S'(t)\\).\n\nFormellement la fonction de densité \\(f(t)\\) s’écrit:\n\\[f(t)=\\lim\\limits_{dt\\to{0}}  \\frac{P(t\\leq{T}&lt; t + dt)}{dt}\\]"
  },
  {
    "objectID": "03-theorie.html#le-risque-instantané-ht",
    "href": "03-theorie.html#le-risque-instantané-ht",
    "title": "3  La théorie",
    "section": "3.5 Le risque instantané \\(h(t)\\)",
    "text": "3.5 Le risque instantané \\(h(t)\\)\nConcept fondamental de l’analyse des durées:\n\\[h(t)=\\lim\\limits_{dt\\to{0}} \\frac{P(t\\leq{T}&lt; t + dt | T\\geq{t})}{dt}\\]\n\n\\(P(t\\leq{T}&lt; t + dt | T\\geq{t})\\) donne la probabilité de survenue de l’évènement sur l’intervalle \\([t,t+dt[\\) conditionnellement à la survie au temps \\(t\\).\n\nEn divisant par \\(dt\\), La quantité obtenue donne alors un nombre moyen d’évènements que connaîtrait un individu durant un très court intervalle de temps.\nA priori cette quantité n’est pas une probabilité. C’est la nature de l’évènement, en particulier sa non récurrence, et la métrique temporelle choisie ou disponible qui peut la rendre assimilable à une probabilité. Tout comme la densité, on est plutôt dans la définition d’un taux (d’où l’expression hazard rate en anglais).\n\nOn peut également écrire: \\(h(t)=\\frac{f(t)}{S(t)}=\\frac{F'(t)}{S(t)}=-\\frac{S'(t)}{S(t)}\\)\nOn remarque que la fonction de risque n’est pas une probabilité car \\(\\frac{f(t)}{S(t)}\\) ne peut pas contraindre la valeur obtenue à ne pas être supérieure à 1.\n\n3.5.1 Le risque cumulé \\(H(t)\\)\nLe risque cumulé est égal à :\n\\[H(t)=\\int_{0}^{t} h(u)du = -log(S(t))\\]\nOn peut alors réécrire toutes les autres quantités à partir de celle-ci:\n\n\\(S(t)=e^{-H(t)}\\)\n\n\\(F(t)=1-e^{-H(t)}\\)\n\n\\(f(t)=h(t)\\times{e^{-H(t)}}\\)\n\nExemple avec la loi exponentielle (risque constant)\nSi on pose que le risque est strictement constant au cours du temps: \\(h(t)=a\\). Cette forme du risque suit une loi exponentielle. Cette situation est, par exemple, typique des processus dits sans mémoire comme la durée de vie des ampoules:\n\n\\(h(t)=a\\)\n\n\\(H(t)=a\\times{t}\\)\n\n\\(S(t)=e^{-a\\times{t}}\\)\n\n\\(F(t)=1-e^{-a\\times{t}}\\)\n\n\\(f(t)=a\\times{e^{-a\\times{t}}}\\)\n\n\n\n\nGrandeurs de la loi exponentielle avec h(t)=0.04\n\n\nApplication: risque et échelles temporelles:\nAttention on sort ici très clairement de la durée continue, il s’agit seulement de manipuler les concepts et de voir la dépendance de la mesure du risque à l’échelle temporelle choisie ou disponible.\n\nDurant les mois d’hiver, entre le 1er janvier et le 1er avril [3 mois], la probabilité d’attraper un rhume chaque mois est de 48% (il s’agit bien d’un risque). Quelle est le risque d’attraper le rhume durant la saison froide?\n\\(\\frac{0.48}{1/3}=1.44\\). On peut donc s’attendre a attraper 1.44 rhume durant la période d’hiver.\nOn passe une année en vacances dans une région où la probabilité de décéder chaque mois est évaluée à 33%. Quelle est le risque de décéder pendant cette année sabbatique? \\(\\frac{0.33}{1/12}=3.96\\)\n\nLe risque peut donc être supérieur à 1. C’est donc plutôt un taux tel qu’il est défini généralement. En soit cela ne pose pas de problème comme il s’agit d’un nombre moyen d’évènements espérés (exemple: taux de fécondité), mais pour des évènements qui ne peuvent pas se répéter, évènements dits absorbants, l’interprétation n’est pas très intuitive.\nLe risque étant constant, on peut prendre son inverse qui mesure la durée moyenne (espérée) jusqu’à l’occurence de l’évènement.\nOn retrouve donc un concept classique en analyse démographique comme l’espérance de vie (survie): la question n’est pas de savoir si on va mourir ou non, ce risque indépendamment de la durée étant par définition égal à 1, mais jusqu’à quand on peut espérer survivre.\n\nPour le rhume, la durée moyenne est de \\((1.44^{-1}=0.69\\) du trimestre hivernal, soit approximativement le début du mois de mars.\nPour l’année sabbatique, la durée moyenne de survie est de \\(3.96^{-1}=0.25\\) d’une année soit 3 mois après l’arrivée dans la région.\n\nExercice\n\nOn a une population de 100 cochons d’Inde.\nOn analyse leur mortalité (naturelle).\n\nIci l’analyse est en temps discret.\nLa durée représente le nombre d’année de vie.\nIl n’y a pas de censure à droite.\n\n\n\n\nDurée\nNombre de décès\n\n\n\n\n1\n1\n\n\n2\n1\n\n\n3\n3\n\n\n4\n9\n\n\n5\n30\n\n\n6\n40\n\n\n7\n10\n\n\n8\n3\n\n\n9\n2\n\n\n10\n1\n\n\n\nN=100\nA quel âge le risque de mourir des cochons d’Inde est-il le plus élevé? Quelle est la valeur de ce risque?"
  },
  {
    "objectID": "03-theorie.html#remarques-complémentaires",
    "href": "03-theorie.html#remarques-complémentaires",
    "title": "3  La théorie",
    "section": "3.6 Remarques complémentaires",
    "text": "3.6 Remarques complémentaires\n\n3.6.1 Formes typiques de la fonction de survie\nUne des propriétés de la fonction de survie ou de séjour est qu’elles tendent vers 0. A la lecture du graphique suivant, cela peut correspondre à la forme de la courbe S2, bien que le % de survivant tend à baisser de moins en moins à mesure que la durée augmente. Deux cas limites doivent être considéré.\n\n\n\nFonction de survie: 3 situtation typiques\n\n\n\nS1: très peu d’évènements et la fonction de séjour suit une asymptote nettement supérieur à 0 ( \\(\\lim\\limits_{t\\to{\\propto}}S(t)=a\\) avec \\(a&gt;0\\)). La question est plus délicate car on interroge l’exposition au risque d’une partie de l’échantillon ou, dit autrement on peut penser qu’une fraction est immunisé au risque. Cette problématique est rapidement posée en fin de formation.\nS2: la situation attendue\nS3: La survie tombe à 0 très/trop rapidement: il n’y a donc pas ou presque pas de durée (par exemple presque tout l’échantillon observe l’évènement la première année de l’exposition). Les méthodes en temps continue ne sont a priori pas adaptées à ce genre de situation. Si on dispose d’une information plus fine pour dater les évènements, la fonction de séjour pourra reprendre une forme plus “standard”. Dans le graphique, \\(S(t=1)=0.4\\) , \\(S(t=2)=0.025\\), mais si on dispose par exemple de 10 points d’observations supplémentaires dans chaque durée groupée:\n\n\n\n\nFonction de survie et modification de la métrique temporelle\n\n\n\n\n3.6.2 Absence de censures à droites\nLes méthodes qui vont être présentées plus tard gèrent la présence de censures à droite. S’il n’y en a pas, elle restent néanmoins parfaitement valables. L’absence de censure facilite certaines analyses, par exemple celles des fonctions de séjour où le calcul direct des durées moyennes est rendu possible.\n\n\n3.6.3 Utilisation des pondérations dans un schema retrospectif avec des biographies longues\nUne question assez récurrente concerne l’utilisation des poids de sondage dans les analyses de durées avec longueurs biographiques souvent assez longues. Leur utilisation ne me semble pas recommandée voire à exclure sauf exceptions. En effet les pondérations sont générées au moment de l’enquête, alors que les évènements étudiés peuvent remonter dans un passé plus ou moins lointain pour une partie de la population analysée. Si on regarde de plus près, la création de poids longitudinaux ne résoudrait pas grand chose , les pondérations devant être recalculées à chaque moment d’observation ou à chaque moment où des évènements se produisent. Par ailleurs on mélangerait régulièrement à un instant donné des personnes issues de générations différentes ce qui rend impossible tout calage sur des caractéristiques d’un population. Supposons une personne âgée de 25 ans et un personne âgée de 70 ans au moment de l’enquête en 2022, avec un début d’observation à l’âge de 18 ans . A 20 ans (\\(t=2\\)), pour la première personne les caractéristiques de la population sont celles de 2017, pour celle de 70 ans celles de 1972. On fait comment??????"
  },
  {
    "objectID": "04-fsurvie.html#les-fonctions-de-survieséjour",
    "href": "04-fsurvie.html#les-fonctions-de-survieséjour",
    "title": "4  Estimations des fonctions de survie",
    "section": "4.1 Les fonctions de survie/séjour",
    "text": "4.1 Les fonctions de survie/séjour\n\n4.1.1 Les variables d’analyse\nOn a un échantillon aléatoire de \\(n\\) individus avec:\n\nDes indicateurs de fin d’épisode \\(e_1,e_2,....,e_k\\) avec \\(e_i=0\\) si censure à droite et \\(e_i=1\\) si évènement observé pendant la période d’observation.\nDes durées d’exposition au risque \\(t_1,t_2,....,t_k\\) jusqu’à l’évènement ou la censure.\nEn théorie, il ne peut pas y avoir d’évènement en \\(t=0\\).\n\n\n\n4.1.2 Calcul de la fonction de survie\nRappel: La fonction de survie donne la probabilité que l’évènement survienne après \\(t_i\\), soit \\(S(t_i)=P(T&gt;t_i)\\). Pour survivre en \\(t_i\\), il faut donc avoir survécu en \\(t_{i-1}\\), \\(t_{i-2}\\), …., \\(t_{1}\\).\nLa fonction de survie renvoie donc des probabilités conditionnelles: on survit en \\(t_i\\) conditionnellement au fait d’y avoir survécu avant. Il s’agit donc d’un produit de probabilités.\nSoit \\(d_i=\\sum e_i\\) le nombre d’évènements observé en \\(t_i\\) et \\(r_i\\) la population encore soumise au risque en \\(i\\). On peut mesurer l’intensité de l’évènement en \\(t_i\\) en calculant le quotient \\(q(t_i)=\\frac{d_i}{r_i}\\).\nSi le temps est strictement continu on devrait toujours avoir \\(q(t_i)=\\frac{1}{r_i}\\).\n\\(S(t_i) = (1 - \\frac{d_i}{r_i})\\times{S(t_{i-1})} = S(t_i) = (1 - q(t_i))\\times{S(t_{i-1})}\\). En remplaçant \\(S(t_{i-1})\\) par sa valeur: \\(S(t_i) = (1 - \\frac{d_i}{r_i})\\times(1 - \\frac{d_{i-1}}{r_{i-1}})\\times{S(t_{i-2})}\\).\nAu final, en remplaçant toutes les expressions de la survie jusqu’en \\(t_0\\) (\\(S(0)=1\\)):\n\\[S(t_i)=\\displaystyle \\prod_{t_i\\leq{k}} (1-q(t_i))\\]\n\n\n\n\n\n\nApplication pour la suite du support\n\n\n\n\nOn va analyser le risque de décéder (la survie) de personnes souffrant d’une insuffisance cardiaque. Le début de l’exposition est leur inscription dans un registre d’attente pour une greffe du coeur.\nLes covariables sont dans un premier temps toutes fixes: l’année (year) et l’âge (age) à l’entrée dans le registre, et le fait d’avoir été opéré pour un pontage aorto-coronarien avant l’inscription (surgery).\nLe début de l’exposition au risque est l’entrée dans le registre, la durée est mesurée en jour (stime). La variable évènement/censure est le décès (died). Les durées de la variable stime ont été regroupée par période de 30 jours pour réaliser des analyses à durée discrete. Cette nouvelle variable de durée a été appelé mois.\nL’introduction d’une dimension dynamique, la greffe, est donnée par les informations contenues dans les variables transplant et wait.\nLa variable compet est une information simulée pour réaliser des analyses en risques concurrents.\nLes bases en format .csv, .sas7bdat et .dta sont disponibles dans ce dépôt [lien]\n\nExtrait de la base:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nyear\nage\ndied\nstime\nsurgery\ntransplant\nwait\nmois\ncompet\n\n\n\n\n15\n68\n53\n1\n1\n0\n0\n0\n1\n1\n\n\n43\n70\n43\n1\n2\n0\n0\n0\n1\n1\n\n\n61\n71\n52\n1\n2\n0\n0\n0\n1\n1\n\n\n75\n72\n52\n1\n2\n0\n0\n0\n1\n1\n\n\n102\n74\n40\n0\n11\n0\n0\n0\n1\n0\n\n\n74\n72\n29\n1\n17\n0\n1\n5\n1\n2"
  },
  {
    "objectID": "04-fsurvie.html#la-méthode-actuarielle",
    "href": "04-fsurvie.html#la-méthode-actuarielle",
    "title": "4  Estimations des fonctions de survie",
    "section": "4.2 La méthode actuarielle",
    "text": "4.2 La méthode actuarielle\n\nEstimation sur des intervalles définies par l’utilisateur.\nMéthode dite «continue», estimation en milieu d’intevalle.\nMéthode apropriée lorsque la durée est mesurée de manière discrète/groupée.\nMéthode, hélas, quasiment abandonnée dans les sciences sociales où les durées sont plus rarement mesurées de manière exacte. L’absence de test de comparaison des fonctions de survie n’y est pas étranger, tout comme le lien de la méthode suivante (Kaplan-Meier) avec le modèle de Cox.\nContrairement à la méthode de Cox, la méthode actuarielle permet de calculer les quantiles de la durée.\n\n\n4.2.1 Estimation\nEchelle temporelle\nLa durée est divisée en \\(J\\) intervalles, en choisissant \\(J\\) points: \\(t_0&lt;t_1&lt;...&lt;t_J\\) avec \\(t_{J+1}=\\infty\\).\nCalcul du Risk set\n\nA \\(t_{min}=0\\), \\(n_0=n\\) individus soumis au risque: \\(r_0=n_0\\).\nLe nombre d’exposé.e.s au risque sur un intervalle est calculé en soustrayant la moitié des cas censurés sur la longueur de l’intervalle: \\(r_i=n_i- 0.5\\times{c_i}\\), avec \\(n_i\\) le nombre de personnes soumises au risque au début de l’intervalle et \\(c_i\\) le nombre d’observations censurées sur la longueur de l’intervalle. On suppose donc que les observations censurées \\(c_i\\) sont sorties de l’observation uniformément sur l’intervalle. Les cas censurés le sont en moyenne au millieu de l’intervalle. \n\nCalcul de \\(S(t_i)\\)\nOn applique la méthode de la section précédente avec:\n\\[q(t_i)=\\frac{d_i}{n_i - 0.5\\times c_i}\\]\nCalcul de la durée médiane (ou autre quantiles)\nRappel: en raison de la présence de censures à droite, le dernier intervalle étant ouvert jusqu’à la dernière sortie d’observation, il n’est pas conseillé de calculer des durées moyennes. On préfère utiliser la médiane ou tout autre quantile lorsqu’ils sont calculables.\nDéfinition: il s’agit de la durée telle que \\(S(t_i)=0.5\\).\nCalcul: Comme on applique une méthode continue et monotone à l’intérieur d’intervalles, on ne peut pas calculer directement un point de coupure qui correspond à 50% de survivants. On doit donc trouver ce point par interpolation linéaire dans l’intervalle \\([t_i;t_{i+1}[\\) avec \\(S(t_{i+1})\\leq0.5\\) et \\(S(t_{i})&gt;0.5\\).\nR-Stata-Sas-Python\n\nRStataSasPython\n\n\nLes fonctions de survie avec la méthode dite actuarielle sont estimables avec le package discSurv. Avec le temps, il s’est étoffé, on peut maintenant paramatrer des intervalles (programmation pénible), mais les quantiles de la durée ne sont toujours pas estimables, ce qui est bien dommage.\n\n\nCommande ltable, avec en option la paramétrisation des intervalles de durées. Voir la commande externe qlt (MT) qui calcule les durées médianes (+ autres quartiles) et qui recalcule la fonction de séjour avec une définition des intervalles de durées identique à celle de SAS.\n\n\nSous une proc lifetest avec en option method=lifetable. On peut paramétrer les intervalles d’estimation avec l’option width.\n\n\nA l’heure actuelle, aucune fonction à ma connaissance\n\n\n\n\n\n4.2.2 Application\nLes résultats qui suivent ont été estimés avec Stata en retenant la définition des bornes de Sas, plus pertinente à mon sens, avec des intervalles fixes de 30 jours.\n\n\nAfficher le tableau des estimateurs\n     +----------------------------------------------+\n     |   t0     t1   survival CI 95% low  CI 95% up |\n     |----------------------------------------------|\n  1. |    0     30          1          .          . |\n  2. |   30     60   .7853659   .6925991   .8530615 |\n  3. |   60     90   .6461871   .5449008   .7304808 |\n  4. |   90    120    .525027   .4232338   .6170507 |\n  5. |  120    150   .4740535   .3737563   .5677139 |\n     |----------------------------------------------|\n  6. |  150    180   .4636348   .3637283   .5575485 |\n  7. |  180    210   .4425605   .3435417   .5368989 |\n  8. |  210    240   .4105681   .3132064   .5052779 |\n  9. |  240    270   .3997637   .3030412   .4945301 |\n 10. |  270    300   .3888113   .2927645   .4836136 |\n     |----------------------------------------------|\n 11. |  300    330   .3665935   .2720434   .4613676 |\n 12. |  330    360   .3554846   .2617823   .4501585 |\n 13. |  360    390   .3216289   .2308275   .4157428 |\n 14. |  390    420   .3216289   .2308275   .4157428 |\n 15. |  420    450   .3216289   .2308275   .4157428 |\n     |----------------------------------------------|\n 16. |  480    510   .3216289   .2308275   .4157428 |\n 17. |  510    540   .3216289   .2308275   .4157428 |\n 18. |  540    570   .3216289   .2308275   .4157428 |\n 19. |  570    600   .3216289   .2308275   .4157428 |\n 20. |  600    630   .3059397   .2154747   .4009653 |\n     |----------------------------------------------|\n 21. |  660    690   .3059397   .2154747   .4009653 |\n 22. |  720    750   .2884574   .1981834   .3848506 |\n 23. |  840    870   .2704288   .1806664   .3680736 |\n 24. |  900    930   .2517786   .1628919   .3505543 |\n 25. |  930    960   .2517786   .1628919   .3505543 |\n     |----------------------------------------------|\n 26. |  960    990   .2517786   .1628919   .3505543 |\n 27. |  990   1020   .2288896   .1404089   .3303913 |\n 28. | 1020   1050   .2060007   .1191749   .3093143 |\n 29. | 1140   1170   .1831117   .0991601   .2873401 |\n 30. | 1320   1350   .1831117   .0991601   .2873401 |\n     |----------------------------------------------|\n 31. | 1380   1410   .1831117   .0991601   .2873401 |\n 32. | 1560   1590   .1464894   .0645215   .2602391 |\n 33. | 1770   1800   .1464894   .0645215   .2602391 |\n 34. | 1800      .   .1464894   .0645215   .2602391 |\n     +----------------------------------------------+\n\n\n\nQuantiles de la fonction de séjour type actuarielle - Bornes Sas\n\n\nS(t)\nt\n\n\n\n\n0.90\n13.977\n\n\n0.75\n37.623\n\n\n0.50\n104.729\n\n\n0.25\n906.993\n\n\n0.10\n.\n\n\n\n\n\n\nCourbe de survie: estimation méthode actuarielle\n\n\nLecture des résultats: 102 jours après leur inscription dans le registre d’attente pour une greffe, 50% des malades sont toujours en vie. Au bout de 914 jours, 75% sont décédés."
  },
  {
    "objectID": "04-fsurvie.html#la-méthode-de-kaplan-meier",
    "href": "04-fsurvie.html#la-méthode-de-kaplan-meier",
    "title": "4  Estimations des fonctions de survie",
    "section": "4.3 La méthode de Kaplan-Meier",
    "text": "4.3 La méthode de Kaplan-Meier\n\nL’approche qui exploite toute l’information disponible est celle dite de Kaplan-Meier (KM).\nIl y a autant d’intervalles que de durées où l’on observe au moins un évènement.\nAu lieu d’utiliser des intervalles prédéterminés, l’estimateur KM va définir un intervalle entre chaque évènement enregistré.\nLa fonction de survie estimée par la méthode KM est une fonction en escalier (stairstep), d’où une estimation dite “discrète”.\nPour chaque intervalle, on compte le nombe d’évènements et le nombre de censures.\nMéthode adaptée pour une mesure de la durée de type continue.\n\n\n4.3.1 Estimation\nDéfinition du Risk Set (\\(r_i\\))\nS’il y a à la fois des évènements et des censures à une durée \\(t_i\\), les observations censurées sont considérées comme exposées au risque à ce moment, comme si elles étaient censurées très rapidement après. C’est la principale caractéristique de cette méthode, appelé également l’estimateur product-limit\n\\[r_i=r_{i-1}-d_{i-1}-c_{i-1}\\]\n\nCalcul de \\(q_i\\)\n On applique la méthode de la section précédente avec:\n\\[q_i=\\frac{d_i}{r_{i-1}-d_{i-1}-c_{i-1}}\\] Remarque: la variance de l’estimateur est obtenu par la méthode dite de Greenwood. Il n’y a pas d’intérêt particulier de la décrire dans ce support.\nRécupération de la médiane\nIl n’y a pas de méthode pour calculer directement la durée médiane (ou tout autre quantile) contrairement à l’approche actuarielle.\nLa définition retenue est conventionnelle. On va prendre la valeur de la durée qui se situe juste en dessous de 50% de survivant.e.s. Elle est donc définie tel que \\(S(t)\\leq0.5\\). Attention, il n’est pas impossible que le % de survivant.e.s soit bien en deçà de 50% pour l’obtention cette durée médiane.\nR-Stata-Sas-Python\n\nRStataSASPython\n\n\nLes estimateurs sont obtenus avec fonction survfit du package survival. On peut obtenir des rendus graphiques de meilleures qualité avec le package survminer (fonction ggsurvplot)\n\n\nAprès avoir appelé les variables de durée et de censure en mode survival avec stset), le tableau des estimateurs est obtenu avec la commande sts list et le graphique avec sts graph.\n\n\nL’estimation de Kaplan-Meier est affichée par défaut par la proc lifetest. Warning : le tableau affiché par SAS est particulièrement pénible à lire voire illisible, en particulier lorsque le nombre de censures est élevé, une ligne étant ajoutée pour chaque observation censurée. Je conseille de ne pas afficher cette partie de l’output (se reporter à la section SAS du chapitre programmation). On récupère pour le reste de l’output les valeurs de la durée pour S(t) =(.75,.5,.25) ainsi que le graphique, ce qui est suffisant.\n\n\nLes resultats sont donnés dans la librairie lifeline par des fonctions au nom interminable. Je conseille plutôt l’utilisation de la librairie statmodels (se reporter à la section dédiée à Python).\n\n\n\n\n\n4.3.2 Application\nOn reprend l’exemple précédent.\n\n\nAfficher le tableau des estimateurs\nTime    Total   Fail   Lost           Function     Error     [95% Conf. Int.]\n-------------------------------------------------------------------------------\n     1      103      1      0             0.9903    0.0097     0.9331    0.9986\n     2      102      3      0             0.9612    0.0190     0.8998    0.9852\n     3       99      3      0             0.9320    0.0248     0.8627    0.9670\n     5       96      2      0             0.9126    0.0278     0.8388    0.9535\n     6       94      2      0             0.8932    0.0304     0.8155    0.9394\n     8       92      1      0             0.8835    0.0316     0.8040    0.9321\n     9       91      1      0             0.8738    0.0327     0.7926    0.9247\n    11       90      0      1             0.8738    0.0327     0.7926    0.9247\n    12       89      1      0             0.8640    0.0338     0.7811    0.9171\n    16       88      3      0             0.8345    0.0367     0.7474    0.8937\n    17       85      1      0             0.8247    0.0375     0.7363    0.8857\n    18       84      1      0             0.8149    0.0383     0.7253    0.8777\n    21       83      2      0             0.7952    0.0399     0.7034    0.8614\n    28       81      1      0             0.7854    0.0406     0.6926    0.8531\n    30       80      1      0             0.7756    0.0412     0.6819    0.8448\n    31       79      0      1             0.7756    0.0412     0.6819    0.8448\n    32       78      1      0             0.7657    0.0419     0.6710    0.8363\n    35       77      1      0             0.7557    0.0425     0.6603    0.8278\n    36       76      1      0             0.7458    0.0431     0.6495    0.8192\n    37       75      1      0             0.7358    0.0436     0.6388    0.8106\n    39       74      1      1             0.7259    0.0442     0.6282    0.8019\n    40       72      2      0             0.7057    0.0452     0.6068    0.7842\n    43       70      1      0             0.6956    0.0457     0.5961    0.7752\n    45       69      1      0             0.6856    0.0461     0.5855    0.7662\n    50       68      1      0             0.6755    0.0465     0.5750    0.7572\n    51       67      1      0             0.6654    0.0469     0.5645    0.7481\n    53       66      1      0             0.6553    0.0472     0.5541    0.7390\n    58       65      1      0             0.6452    0.0476     0.5437    0.7298\n    61       64      1      0             0.6352    0.0479     0.5333    0.7206\n    66       63      1      0             0.6251    0.0482     0.5230    0.7113\n    68       62      2      0             0.6049    0.0487     0.5026    0.6926\n    69       60      1      0             0.5948    0.0489     0.4924    0.6832\n    72       59      2      0             0.5747    0.0493     0.4722    0.6643\n    77       57      1      0             0.5646    0.0494     0.4621    0.6548\n    78       56      1      0             0.5545    0.0496     0.4521    0.6453\n    80       55      1      0             0.5444    0.0497     0.4422    0.6357\n    81       54      1      0             0.5343    0.0498     0.4323    0.6261\n    85       53      1      0             0.5243    0.0499     0.4224    0.6164\n    90       52      1      0             0.5142    0.0499     0.4125    0.6067\n    96       51      1      0             0.5041    0.0499     0.4027    0.5969\n   100       50      1      0             0.4940    0.0499     0.3930    0.5872\n   102       49      1      0             0.4839    0.0499     0.3833    0.5773\n   109       48      0      1             0.4839    0.0499     0.3833    0.5773\n   110       47      1      0             0.4736    0.0499     0.3733    0.5673\n   131       46      0      1             0.4736    0.0499     0.3733    0.5673\n   149       45      1      0             0.4631    0.0499     0.3632    0.5571\n   153       44      1      0             0.4526    0.0499     0.3531    0.5468\n   165       43      1      0             0.4421    0.0498     0.3430    0.5364\n   180       42      0      1             0.4421    0.0498     0.3430    0.5364\n   186       41      1      0             0.4313    0.0497     0.3327    0.5258\n   188       40      1      0             0.4205    0.0497     0.3225    0.5152\n   207       39      1      0             0.4097    0.0495     0.3123    0.5045\n   219       38      1      0             0.3989    0.0494     0.3022    0.4938\n   263       37      1      0             0.3881    0.0492     0.2921    0.4830\n   265       36      0      1             0.3881    0.0492     0.2921    0.4830\n   285       35      2      0             0.3660    0.0488     0.2714    0.4608\n   308       33      1      0             0.3549    0.0486     0.2612    0.4496\n   334       32      1      0             0.3438    0.0483     0.2510    0.4383\n   340       31      1      1             0.3327    0.0480     0.2409    0.4270\n   342       29      1      0             0.3212    0.0477     0.2305    0.4153\n   370       28      0      1             0.3212    0.0477     0.2305    0.4153\n   397       27      0      1             0.3212    0.0477     0.2305    0.4153\n   427       26      0      1             0.3212    0.0477     0.2305    0.4153\n   445       25      0      1             0.3212    0.0477     0.2305    0.4153\n   482       24      0      1             0.3212    0.0477     0.2305    0.4153\n   515       23      0      1             0.3212    0.0477     0.2305    0.4153\n   545       22      0      1             0.3212    0.0477     0.2305    0.4153\n   583       21      1      0             0.3059    0.0478     0.2156    0.4008\n   596       20      0      1             0.3059    0.0478     0.2156    0.4008\n   620       19      0      1             0.3059    0.0478     0.2156    0.4008\n   670       18      0      1             0.3059    0.0478     0.2156    0.4008\n   675       17      1      0             0.2879    0.0483     0.1976    0.3844\n   733       16      1      0             0.2699    0.0485     0.1802    0.3676\n   841       15      0      1             0.2699    0.0485     0.1802    0.3676\n   852       14      1      0             0.2507    0.0487     0.1616    0.3497\n   915       13      0      1             0.2507    0.0487     0.1616    0.3497\n   941       12      0      1             0.2507    0.0487     0.1616    0.3497\n   979       11      1      0             0.2279    0.0493     0.1394    0.3295\n   995       10      1      0             0.2051    0.0494     0.1183    0.3085\n\n[Résultats non reportés à partir de t=1000 ]\n-------------------------------------------------------------------------------\n\n\nLa durée durée médiane de survie est \\(t=100\\). Elle correspond à \\(S(t)=0.4940\\).\n\nQuantiles de la fonction de séjour type Kaplan-Meier\n\n\nS(t)\nt\n\n\n\n\n0.90\n6\n\n\n0.75\n36\n\n\n0.50\n100\n\n\n0.25\n979\n\n\n0.1\n.\n\n\n\n\n\n\n\n\nCourbe de survie: estimation méthode Kaplan-Meier\n\n\n\n\n\nCourbe de survie: méthode Kaplan-Meier + CI\n\n\n\n\n\n\n4.3.3 Quantités associées à l’estimateur Kaplan-Meier..\nLe risque cumulé: estimateur de Nelson AAlen\nIl est simplément égal à:\n\\[H(t)=\\sum_{t_i\\leq k}q(t_i)\\]\n\n\n\nRisque cumulé: estimateur Nelson-Aalen\n\n\nLe risque instantané\nNécessite l’estimateur de risque cumulé de Nelson-Aalen. Le risque est obtenu en lissant les différences - toujours positive - entre \\(H(t)\\) par la méthode dite du kernel (cf estimation de la densité des distributions). Elle permet d’obtenir une fonction continue avec la durée (paramétrables sur les largeurs des fenêtres de lissage). D’autres méthodes de lissage sont maintenant possibles, et de plus en plus utilisées, en particulier celles utilisant des splines.\n\n\n\nRisque instantané: estimateur du Kernel\n\n\n\n\n\n\n\n\nNote\n\n\n\nIl n’est pas inutile de noter qu’il n’y a pas de formule toute faite pour obtenir des valeurs du risque instantané. Ce type de méthode par lissage est pleinement paramétrable, par exemple sa fenêtre, ce qui implique que son profil varie d’un paramétrage à l’autre. Le graphique précédent a été fait avec Stata, si on utilisait le package muhaz les différences de paramétrage par défaut font que les courbes ne se confondent pas."
  },
  {
    "objectID": "05-fsurvie_comp.html#tests-du-log-rank",
    "href": "05-fsurvie_comp.html#tests-du-log-rank",
    "title": "5  Tests de comparaison",
    "section": "5.1 Tests du log-rank",
    "text": "5.1 Tests du log-rank\nIl s’agit d’une série de tests qui répondent à la même logique, la seule différence réside dans le poids accordé au début ou à la fin de la période d’observation. Par ailleurs ces différents tests sont plus ou moins sensibles à la distribution des censures à droites entre les sous échantillons et à la non proportionalité des risques.\nDans leur logique, ces tests entrent dans le cadre des tests d’indépendance du Khi2, même si formellement ils relèvent des techniques dites de rang.\nIl s’agira donc de comparer des effectifs observés à des effectifs espérés à chaque moment d’évènement. La principale différence réside dans le calcul de la variance de la statistique du test qui, ici, suit assez logiquement une loi hypergéométrique [proche loi binomiale mais avec tirage avec remise].\n\n5.1.1 Principe de calcul de la statistique de test\n\nEffectifs observés en \\(t_i\\): \\(o_{i1}\\) et \\(o_{i2}\\) sont égaux à \\(d_{i1}\\) et \\(d_{i2}\\), et leur somme pour tous les temps d’évènement à \\(O_1\\) et \\(O_2\\).\nEffectifs expérés (hypothèse nulle \\(H_0\\)): comme pour une statistique du \\(\\chi^2\\) on se base sur les marges, avec le risque set (\\(R_i\\)) en \\(t_i\\) pour dénombrer les effectifs, soit \\(e_{i1}=R_{i1}\\times\\frac{d_i}{R_i}\\) et \\(e_{i2}=R_{i2}\\times\\frac{d_2}{R_i}\\). Leur somme pour tous les temps d’évènement est égale à \\(E_1\\) et \\(E_2\\). Le principe de calcul des effectifs observés reposent donc sur l’hypothèse d’un rapport des risques toujours égal à 1 au cours du temps (hypothèse fondamentale de risques proportionnels).\nStatistique du log-rank: \\((O_1 - E_1) = -(O_2 - E_2)\\).\nStatistique de test: sous \\(H_0\\), \\(\\frac{(O_1 - E_1)^2}{\\sum{v_i}}\\), avec \\(v_i\\) la variance de \\((o_{i1} - e_{i2})\\), suis un \\(\\chi^2(1)\\). Si on teste simultanément la différence de \\(g\\) fonctions de survie, ce qui n’est pas une bonne idée en passant, la statistique de test suis un \\(\\chi^2(g-1)\\).\n\n\n\n5.1.2 Les principaux tests log-rank\nLe principe de construction des effectifs observés et espérés reste le même dans chaque test, les différences résident dans les pondérations (\\(w_i\\)) qui prennent en compte, de manière différente, la taille de la population soumise au risque à chaque durée où au moins un évènement est observé.\n\nTest du log-rank: \\(w_i=1\\)\nIl accorde le même poids à toutes les durées d’évènement. C’est le test standard, le plus utilisé.\nTest de Wilconxon-Breslow-Grehan: \\(w_i=R_i\\)\nLes écarts entre effectifs observés et espérés sont pondérés par la population soumise à risque en \\(t_i\\). Le test accorde plus de poids au début de la période analysée, et il est sensible aux différences de distributions entre les strates des observations censurées.\nTest de Tarone-Ware: \\(w_i=\\sqrt{R_i}\\)\nVariante du test précédent, il atténue le poids accordé aux évènements au début de la période d’observation. Il est par ailleurs moins sensible au problème de la distribution des censures entre les strates.\nTest de Peto-Peto : \\(w_i=S_i\\)\nLa pondération est une variante de la fonction de survie KM (avec \\(R_i=R_i+1\\)). Le test n’est pas sensible au problème de distribution des censures.\nTest de Fleming-Harington: \\(w_i=(S_i)^p\\times(1-S_i)^{q}\\) avec \\(0\\leq{p}\\leq{1}\\) Il permet de paramétrer le poids accordé au début où à la fin de temps d’observation. Si \\(p=q=0\\) on retrouve le test de base non pondéré.\n\nEn pratique/remarques:\n\nLes tests du log-rank sont sensibles à l’hypothèse de risques proportionnels (voir modèle semi-paramétrique de Cox). En pratique si des courbes de séjours se croisent, il est fortement déconseillé de les utiliser. Cela ne signifie pas que si les courbes ne se croisent pas, l’hypothèse de proportionalité des risques est respectée : des rapports de risque peuvent au cours du temps s’intensifier, se réduire ou, le cas échant s’inverser, ce qui est typique d’un croisement.\nEffectuer un test global (multiple/omnibus) sur un nombre important de groupes (ou &gt;2) peut rendre le test très facilement significatif. Il peut être intéressant de tester des courbes deux à deux (idem qu’une régression avec covariable discrète), en conservant un seul degré de liberté. Des méthodes de correction du test multiple sont possibles ou disponibles si on utilise R.\n\nR-Stata-Sas-Python\n\nRStataSasPython\n\n\nOn utilise la fonction survdiff de la librairie survival. Le résultat du test de Peto-Peto est affiché par défaut (rho=1). Si on souhaite utiliser le test non pondéré, on ajoute l’option rho=0. Pour obtenir le résultat d’un test multiple corrigé (plus d’un degré de liberté), on peut utiliser la fonction pairwise_survdiff du package survminer. Cette fonction permet également d’obtenir des tests 2 à 2.\nJe conseille de rester sur l’option Peto-Peto et dans le cas d’une variable à plus de deux modalités, d’utiliser la fonction de survminer pairwise_survdiff.\n\n\nOn utilise la commande sts test avec le nom de la version du test: peto, wilcoxon . Sans préciser le nom de la variante, le test non pondéré est exécuté.\n\n\nLe test non pondéré et la version Wilcoxon sont données avec l’option strata de la proc lifetest. Attention : ne jamais utiliser la version LR Test qui est biaisée. Pour obtenir d’autres versions du test du log-rank, on ajoute /test=all à l’option strata.\n\n\nAvec la librairie lifelines, on utilise la fonction logrank_test. Quatre variantes sont disponibles (Wilcoxon, Tarone-Ware, Peto-Peto et Fleming-Harrigton). On peut également utiliser la fonction duration.survdiff de statmodels (non pondéré, Wilcoxon - appelé ici Breslow- et Tarone-Ware).\n\n\n\n\n\n5.1.3 Application\nOn compare ici l’effet du pontage coronarien sur le risque de décéder depuis l’inscription dans le registre de greffe.\n\n\n\n\n\n\nRésultats des tests du logrank\n\n\nTest\ndf\nChi2\nP&gt;Chi2\n\n\n\n\nNon pondéré\n1\n6.59\n0.0103\n\n\nWilcoxon (Breslow)\n1\n8.99\n0.0027\n\n\nTarone-Ware\n1\n8.46\n0.0036\n\n\nPeto-Peto\n\n8.66\n0.0033\n\n\n\nLes résultats font apparaître que l’opération permet d’augmenter la durée de survie des personnes. Il apparait que la p-value est plus élevée pour test non pondérée. Cela peut-il s’expliquer en regardant les deux courbes de séjours? Qu’en est-il de la proportionalité des risques ???? …. Réponse pendant la formation."
  },
  {
    "objectID": "05-fsurvie_comp.html#comparaison-des-rmst",
    "href": "05-fsurvie_comp.html#comparaison-des-rmst",
    "title": "5  Tests de comparaison",
    "section": "5.2 Comparaison des RMST",
    "text": "5.2 Comparaison des RMST\nRMST: Restricted Mean of Survival Time\nLa comparaison des RMST est une alternative pertinente aux tests du log-rank car elle ne repose pas sur des hypothèses contraignantes (proportionnalité des risques, distribution des censures), et permet une lecture vivante basée sur des espérances de séjour et non sur la lecture d’une simple p-value traduisant l’homogénéité ou non des fonctions de séjour. Par ailleurs les comparaisons sont souples, on peut choisir un ou plusieurs points d’horizon pour alimenter l’analyse.\nPrincipe\n\nL’aire sous la fonction de survie représente la durée moyenne d’attente jusqu’à l’évènement, soit une espérance de survie.\nEn présence de censure à droite, il faut borner la durée maximale \\(t^*&lt;\\infty\\). L’espérance de survie s’interprète donc sur un horizon fini. On est très proche d’une mesure en analyse démographique type « espérance de vie partielle ».\n\\(RMST =\\int_0^{t^*}S(t)dt\\).\nOn peut facilement comparer les RMST de deux groupes, en termes de différence ou de ratio.\nPar défaut on définit généralement \\(t^*\\) à partir le temps du dernier évènement observé. Il est néanmoins possible de calculer le RMST sur des intervalles plus court, ce qui lui permet une véritable souplesse au niveau de l’analyse.\n\nR-Stata-Sas-Python\nAttention, selon les logiciels la durée max par défaut n’est pas la même. Pour R et Sas, il s’agit du dernier évènement observé sur l’ensemble de l’échantillon, alors que Stata prend la durée qui correspond au dernier évènement observé le plus court des deux groupes . Cela affectera légèrement la valeur des Rmst estimées par défaut.\nPour l’exemple, la durée maximale utilisée par R est de 1407 jours alors que pour Stata elle est de 995 jours.\n\nRStataSASPython\n\n\nLibrairie SurvRm2. Programmée par les mêmes personnes que la commande Stata, la fonction proposée n’est pas très souple.\n\n\nCommande externe strmst2. La plus ancienne fonction proposée par les logiciels. Au final plus limitée que la solution Sas. J’ai programmé une commande, diffrmst, qui représente graphiquement les estimations des Rmst pour chaque temps d’évènement, leurs différences et les p-value issues des comparaisons.\n\n\nDisponible depuis la version 15.1 de SAS/Stat (fin 2018). Les estimations et le résultat du test de comparaison sont récupérables très simplement dans une proc lifetest, avec en option **plots=(rmst)** . Bien que sortie tardivement par rapport Stata et R, les résultats sont particulièrement complets.\n\n\nEstimation un peu pénible. A partir de l’estimateur KM obtenu avec la fonction KaplanMeierFitter de lifelines, on peut obtenir les RMST avec la fonction restricted_mean_survival_time. On peut tracer les fonctions, en revanche le test de comparaison n’est pas implémenté.\n\n\n\nApplication\nAvec \\(tmax=1407\\):\n\nEstimation des Rmst pour la variable surgery\n\n\nGroupes\nRMST\nStd. Err\n95% CI\n\n\n\n\n\\(surgery=1\\)\n884.576\n187.263\n517.546 - 1251.605\n\n\n\\(surgery=0\\)\n379.148\n61.667\n258.282 - 500.014\n\n\n\n\nDifférences entre Rmst pour la variable surgery\n\n\n\n\n\n\n\n\nTypes de contraste\nEcarts RMST\nP&gt;|z|\n95% CI\n\n\n\n\n\\(Rmst(surgery1 - surgery0)\\)\n505.428\n0.010\n517.546 - 1251.605\n\n\n\\(Rmst\\left(\\frac{surgery1}{surgery0}\\right)\\)\n2.333\n0.002\n1.383 - 3.937\n\n\n\nIci \\(t^*\\) est égal à 1407 jours, soit la durée qui correspond au dernier décès observé.\nSur un horizon de 1407 jours, ces individus opérés d’un pontage peuvent espérer vivre 884 jours en moyenne, contre 379 jours pour les autres. La durée moyenne de survie est donc 2.3 fois plus importante pour les personnes opérées (rapport des Rmst = 2.3 ), ce qui correspond à une différence de 379 jours.\nLe tableau et le graphique suivant donnent les valeurs des Rmst et les écarts de la variable surgery en faisant varier \\(tmax\\) sur chaque jour où au moins un décès a été observé. Il a été réalisé avec Stata, la durée maximale utilisée a été paramétrée à 1407 jours (idem R, Sas).\nComme le premier décès observé pour les personnes opéré se situe le 165eme jours, il est tout à fait normal que pour ce groupe de personnes la valeur de la Rmst soit identique au jour de décès des individus non opérés.\n\n\n\n\n\n\nNote\n\n\n\nPour la version pdf, seulement une dizaine de points a été sélectionné en raison de la longueur du tableau\n\n\n\n\nAfficher le tableau\n  +--------------------------------------------------------------------------+\n  | _time     _rmst1     _rmst0      _diff    95%CI lower 95%CI upper  pvalue|\n  |--------------------------------------------------------------------------|\n  |--------------------------------------------------------------------------|\n  |     1          1          1          0           0          0          . |\n  |     2          2   1.989011    .010989   -.0104304   .0324084   .3146368 |\n  |     3          3   2.945055   .0549451   -.0009099      .1108   .0538507 |\n  |     5          5   4.791209   .2087912    .0549289   .3626535   .0078217 |\n  |     6          6   5.692307   .3076923    .0995576   .5158269   .0037617 |\n  |--------------------------------------------------------------------------|\n  |     8          8    7.45055   .5494505    .2224352   .8764658   .0009908 |\n  |     9          9   8.318682   .6813186    .2913915   1.071246   .0006156 |\n  |    11         11   10.03297   .9670329    .4461406   1.487925   .0002741 |\n  |    12         12   10.89011    1.10989    .5212656   1.698514   .0002193 |\n  |    16         16   14.27415   1.725846    .8588567   2.592834   .0000956 |\n  |--------------------------------------------------------------------------|\n  |    17         17   15.08677    1.91323    .9769751   2.849484    .000062 |\n  |    18         18   15.88825   2.111745     1.10533   3.118161   .0000391 |\n  |    21         21   18.25931   2.740688    1.516228   3.965148   .0000115 |\n  |    28         28   23.63593   4.364065    2.598741   6.129389   1.26e-06 |\n  |    30         30   25.14985    4.85015    2.924714   6.775586   7.93e-07 |\n  |--------------------------------------------------------------------------|\n  |    31         31   25.89568   5.104324    3.098862   7.109787   6.08e-07 |\n  |    32         32    26.6415   5.358499    3.272218   7.444779   4.80e-07 |\n  |    35         35   28.84508   6.154923    3.825102   8.484744   2.24e-07 |\n  |    36         36    29.5683   6.431698    4.020457   8.842939   1.71e-07 |\n  |    37         37   30.28023   6.719774    4.227545   9.212004   1.26e-07 |\n  |--------------------------------------------------------------------------|\n  |    39         39   31.68147   7.318526    4.664121   9.972931   6.52e-08 |\n  |    40         40    32.3708   7.629202    4.893653   10.36475   4.60e-08 |\n  |    43         43   34.37097   8.629034    5.651719   11.60635   1.34e-08 |\n  |    45         45   35.68181   9.318189    6.177435   12.45894   6.07e-09 |\n  |    50         50   38.90242   11.09758    7.539261    14.6559   9.80e-10 |\n  |--------------------------------------------------------------------------|\n  |    51         51   39.53524   11.46476    7.822028   15.10748   6.89e-10 |\n  |    53         53   40.77829   12.22171    8.410756   16.03267   3.27e-10 |\n  |    58         58   43.82939   14.17061    9.933216     18.408   5.58e-11 |\n  |    61         61   45.62615   15.37385    10.87721   19.87049   2.07e-11 |\n  |    66         66   48.56425   17.43575    12.50275   22.36874   4.28e-12 |\n  |--------------------------------------------------------------------------|\n  |    68         68   49.71689   18.28311      13.175   23.39121   2.30e-12 |\n  |    69         69   50.27061   18.72939    13.53629   23.92248   1.56e-12 |\n  |    72         72   51.89787   20.10213    14.65526   25.54901   4.71e-13 |\n  |    77         77   54.49696   22.50304    16.63758   28.36851   5.51e-14 |\n  |    78         78   55.00547   22.99453    17.04528   28.94377   3.57e-14 |\n  |--------------------------------------------------------------------------|\n  |    80         80   55.99991   24.00009    17.88509   30.11509   1.44e-14 |\n  |    81         81   56.48582   24.51418    18.31722   30.71113   8.88e-15 |\n  |    85         85   58.38429   26.61571    20.09202    33.1394   1.33e-15 |\n  |    90         90   60.70087   29.29913    22.36311   36.23515   2.22e-16 |\n  |    96         96   63.41296   32.58704    25.15034   40.02373          0 |\n  |--------------------------------------------------------------------------|\n  |   100        100   65.17583   34.82418    27.05229   42.59606          0 |\n  |   102        102   66.03465   35.96535     28.0274   43.90329          0 |\n  |   109        109   68.96146   40.03855     31.5203   48.55679          0 |\n  |   110        110   69.37957   40.62043     32.0176   49.22326          0 |\n  |   131        131   77.91607   53.08393    42.67269   63.49517          0 |\n  |--------------------------------------------------------------------------|\n  |   149        149   85.23307   63.76693    51.71735   75.81651          0 |\n  |   153        153   86.81125   66.18875     53.7781    78.5994          0 |\n  |   165        165   91.40231   73.59769    60.11884   87.07655          0 |\n  |   180   178.6364   97.14113   81.49523    66.43188   96.55859          0 |\n  |   186   184.0909   99.43666   84.65425     68.8452   100.4633          0 |\n  |--------------------------------------------------------------------------|\n  |   188   185.7273   100.2018   85.52544    69.46069   101.5902          0 |\n  |   207   201.2727   107.2365    94.0362    75.10156   112.9708          0 |\n  |   219   211.0909   111.5314   99.55952    78.49335   120.6257          0 |\n  |   263   247.0909   126.7362   120.3547     90.2882   150.4212   4.22e-15 |\n  |   265   248.7273   127.4026   121.3246    90.82352   151.8258   6.44e-15 |\n  |--------------------------------------------------------------------------|\n  |   285   265.0909   134.0671   131.0238     96.0849   165.9628   1.98e-13 |\n  |   308   283.9091   141.1416   142.7675    102.6688   182.8662   2.99e-12 |\n  |   334   305.1818   148.8057   156.3761    110.3439   202.4082   2.77e-11 |\n  |   340   310.0909   150.4975   159.5934    112.1866   207.0003   4.16e-11 |\n  |   342   311.7273   151.0358   160.6915    112.8294   208.5536   4.69e-11 |\n  |--------------------------------------------------------------------------|\n  |   370   332.0909   158.5717   173.5192    119.5852   227.4532   2.87e-10 |\n  |   397   351.7273   165.8385   185.8887    125.7134   246.0641   1.41e-09 |\n  |   427   373.5454   173.9127   199.6327    132.2074    267.058   6.51e-09 |\n  |   445   386.6364   178.7573   207.8791    135.9845   279.7736   1.45e-08 |\n  |   482   413.5454   188.7155     224.83    143.5408   306.1191   5.93e-08 |\n  |--------------------------------------------------------------------------|\n  |   515   437.5454   197.5971   239.9483    150.1031   329.7935   1.65e-07 |\n  |   545   459.3636   205.6714   253.6923    155.9623   351.4222   3.62e-07 |\n  |   583        487   215.8987   271.1013    163.2743   378.9283   8.32e-07 |\n  |   596   494.8788   219.3976   275.4812    164.6331   386.3293   1.11e-06 |\n  |   620   509.4243   225.8569   283.5673     166.951   400.1836   1.88e-06 |\n  |--------------------------------------------------------------------------|\n  |   670   539.7273    239.314   300.4133    171.1152   429.7114   5.27e-06 |\n  |   675   542.7576   240.6597   302.0979    171.4897   432.7061   5.80e-06 |\n  |   733   577.9091    254.969   322.9401     176.861   469.0191   .0000147 |\n  |   841   643.3636   279.1917   364.1719    187.8796   540.4643   .0000515 |\n  |   852   650.0303   281.6588   368.3715    188.9058   547.8372   .0000575 |\n  |--------------------------------------------------------------------------|\n  |   915   688.2121   294.2187   393.9934    196.3119   591.6749   .0000937 |\n  |   941   703.9697   299.4022   404.5675    199.2493   609.8857   .0001125 |\n  |   979        727    306.978    420.022    203.4389   636.6051   .0001441 |\n  |   995   734.7576   310.1678   424.5898    204.0643   645.1152   .0001609 |\n  |  1032   748.2121   317.5443   430.6678    202.7468   658.5889   .0002127 |\n  |--------------------------------------------------------------------------|\n  |  1141   787.8485   335.6531   452.1953    200.7097    703.681   .0004248 |\n  |  1321    853.303   365.5577   487.7454    191.5434   783.9473   .0012492 |\n  |  1386   876.9394   376.3565   500.5829    186.9499   814.2158   .0017585 |\n  |  1400   882.0303   378.2173    503.813    186.4392   821.1869   .0018625 |\n  |  1407   884.5757   379.1476   505.4281    186.1745   824.6817   .0019162 |\n  +--------------------------------------------------------------------------+\n\n\n\n\n\nComparaison des Rmst à chaque jour où au moins un décès est observé"
  },
  {
    "objectID": "06-intro_mod.html",
    "href": "06-intro_mod.html",
    "title": "6  Introduction",
    "section": "",
    "text": "7 Proprortionalité des risques\nLa spécification usuelle d’un modèle à risque proportionnel est:\n\\[h(t)=h_0(t)\\times e^{X^{'}b}\\]\nLe risque de base\n\\(h(t)=h_0(t)\\) donc \\(e^{X^{'}b}=1\\). Observations pour lesquelles \\(X=0\\)\nRisques proportionnels\nCette hypothèse stipule l’invariance dans la durée du rapport des risques (hazard ratio).\nExemple:\nAvec une seule covariable \\(X\\) introduite au modèle, et 2 observations disons \\(A\\) et \\(B\\):\nLe rapport des risques entre \\(A\\) et \\(B\\) est simplement égal à:\n\\[\\frac{h_A(t)}{h_B(t)}= \\frac{e^{bX_A}}{e^{bX_B}}=e^{b(X_A-X_B)}\\]\nAutrement dit, cette proportionnalité des risques est la traduction d’une absence d’interaction entre les rapports de risques estimés par un modèle à risque proportionnel et la durée (ou une fonction de celle-ci).\nSi on part d’un modèle tel que \\(h_0(t)=0.1\\) quelque soit \\(t\\) (baseline à risque constant).\nSi \\(h_1(t)\\) est lui même constant, le rapport entre \\(h_1(t)\\) et \\(h_0(t)\\) sera lui même constant dans la durée. On dit que les risques sont proportionnels. Ici, \\(h_1(t)=0.2\\) quel que soit \\(t\\), le rapport des risques est toujours égal à \\(\\frac{0.2}{0.1}=2=e^{b}\\). Le paramètre estimé par un modèle à risque proportionnel sera égal à \\(log(2)=0.69\\).\nPour \\(h_{1b}(t)\\), le risque augmente de manière à un rythme constant (linéaire): \\(h_{1b}(1)=0.15\\) et \\(h_{1b}(1000)=0.25\\). Comme \\(h_0(t)*\\) est constant, le rapport des risques s’accroît également. On dit que les risques ne sont pas proportionnels.\nSi on est dans le deuxième cas de figure, un modèle à risque proportionnel estimera un rapport toujours égal à 2. Il estimera un rapport moyen sur la période d’observation."
  },
  {
    "objectID": "06-intro_mod.html#footnotes",
    "href": "06-intro_mod.html#footnotes",
    "title": "6  Introduction",
    "section": "",
    "text": "On rappelera qu’en durée continue, seule positivité du risque doit être assurée, d’où l’expression hazard rate↩︎"
  },
  {
    "objectID": "07-cox.html#le-modèle-semi-paramétrique-de-cox",
    "href": "07-cox.html#le-modèle-semi-paramétrique-de-cox",
    "title": "7  Le modèle de Cox",
    "section": "7.1 Le modèle semi-paramétrique de Cox",
    "text": "7.1 Le modèle semi-paramétrique de Cox\n\n7.1.1 La vraisemblance partielle et estimation des paramètres\nOn se situe dans une situation où la durée est mesurée sur une échelle strictement continue. Il ne peut donc y avoir qu’un seul évènement observé en \\(t_i\\) (idem pour la censure).\nOn peut représenter le processus aléatoire d’une analyse de survie en présence de censure à droite, avec l’équation de vraisemblance suivante:\n\\[L_i=f(t_i)^{\\delta_i}S(t_i)^{1-\\delta_i}\\]\n\n\\(f(t_i)\\) est la valeur de la fonction de densité en \\(t_i\\)\n\\(S(t_i)\\) est la valeur de la fonction de survie en \\(t_i\\)\n\\(\\delta_i=1\\) si l’évènement est observé: \\(L_i=f(t_i)\\)\n\\(\\delta_i=0\\) si l’observation est censurée: \\(L_i=S(t_i)\\)\n\nVraisemblance partielle de Cox\nComme \\(f(t_i)=h(t_i)\\times S(t_i)\\) 1, on obtient: \\(L_i=[h(t_i)S(t_i)]^{\\delta_i}S(t_i)^{1-\\delta_i} = h(t_i)^{\\delta_i}S(t_i)\\).\nPour \\(i=1,2,.....,n\\), la vraisemblance s’ecrit donc: \\(L_i=\\prod_{i=1}^{n}h(t_i)^{\\delta_i}S(t_i)\\).\nOn peut réécrire cette vraisemblance en la multipliant et en la divisant par: \\(\\sum_{j\\in R_i}h(t_i)\\), où \\(j\\in R_i\\) est l’ensemble des observations soumises au risque en \\(t_i\\).\n\\[L=\\prod_{i=1}^{n}\\left[h(t_i)\\frac{\\sum_{j\\in R}h(t_i)}{\\sum_{j\\in R}h(t_i)}\\right]^{\\delta_i}S(t_i)= \\prod_{i=1}^{n}\\left[\\frac{h(t_i)}{\\sum_{j\\in R_i}h(t_i)}\\right]^{\\delta_i}\\sum_{j\\in R_i}h(t_i)^{\\delta_i}S(t_i)\\]\nLa vraisemblance partielle retient seulement le premier terme de la vraisemblance, soit:\n\\[PL=\\prod_{i=1}^{n}\\left[\\frac{h(t_i)}{\\sum_{j\\in R}h(t_i)}\\right]^{\\delta_i}\\]\nUne fois remplacée la valeur de \\(h(t_i)\\) par son expression en tant que modèle à risques proportionnels, la vraisemblance partielle ne dépendra plus de la durée. Mais elle va dépendre de l’ordre d’arrivée des évènements, c’est à dire leur rang.\nRemarque: pour les observations censurées(\\(\\delta_i=0\\)), \\(PL=1\\). Toutefois, ces censures à droite entrent dans l’expression \\(\\sum_{j\\in R}h(t_i)\\) tant qu’elles sont soumises au risque.\nEn remplaçant donc \\(h(t_i)\\) par l’expression \\(h_0(t)e^{X_i^{'}b}\\):\n\\[PL=\\prod_{i=1}^{n}\\left[\\frac{h_0(t)e^{X_{i}^{'}b}}{\\sum_{j\\in R_i}h_0(t)e^{X_{j}^{'}b}}\\right]^{\\delta_i} =\\prod_{i=1}^{n}\\left[\\frac{e^{X_i^{'}b}}{\\sum_{j\\in R_i}e^{X_{j}^{'}b}}\\right]^{\\delta_i}\\]\nL’expression \\(\\frac{e^{Xb}}{\\sum_{j\\in R}e^{Xb}}\\) est donc bien une probabilité, et la vraisemblance partielle est donc bien un produit de probabilités. Pour un individu ayant connu l’évènement, la contribution à la vraisemblance partielle est la probabilité que l’individu observe l’évènement en \\(t_i\\) sachant qu’un évènement (et un seul) s’est produit.\n\nSi \\(\\delta_i = 0\\): \\(PL_i = 1\\)\nSi \\(\\delta_i = 1\\): \\(PL_i =\\frac{e^{X_i^{'}b}}{\\sum_{j\\in R_i}e^{X_{j}^{'}b}}\\)\n\nCondition nécessaire: pas d’évènement simultané: en présence d’évènements mesurés simultanément, l’estimation de la vraisemblance doit faire l’objet d’une correction.\nCorrection de la vraisemblance avec des évènements simultanés:\n\nLa méthode dite exacte: Comme il ne doit pas y avoir d’évènement simultané, on va introduire à la vraisemblance partielle toutes les permutations possibles des évènements observés au même moment. Bien qu’en \\(t_i\\) on observe au même moment l’évènement pour 2 observations (A,B) une métrique temporelle plus précise permettrait de savoir si A s’est produit avant B ou B s’est produit avant A (2 permutations). Comme le nombre de permutations est calculé à l’aide d’une factorielle 2, avec 3 évènements mesurés simultanément, on obtient 6 permutations (\\(3\\times2\\times1\\)). Problème: le nombre de permutations pour chaque \\(t_i\\) peut devenir très vite particulièrement élevé. Par exemple pour 10 évènements simultanés, le nombre de permutations est égal à 3,628,800. Le temps de calcul devient extrêmement long, et ce type de correction totalement inopérant.\nLa méthode dite de Breslow: il s’agit d’une approximation de la méthode exacte permettant de ne pas avoir à intégrer chaque permutation. Cette approximation est utilisée par défaut par les logiciels Sas et Stata.\nLa méthode dite d’Efron: elle corrige l’approximation de Breslow, et est jugée plus proche de la méthode exacte. C’est la méthode utilisée par défaut avec le logiciel R, et elle est disponible avec les autres applications.\n\n\n\n7.1.2 Estimation des paramètres\nOn utilise la méthode habituelle, à savoir la maximisation de la log-vraisemblance (ici partielle).\n\nConditions de premier ordre: calcul des équations de score à partir des dérivées partielles. Solution: \\(\\frac{\\partial log(PL)}{\\partial{b_k}}=0\\). On ne peut pas obtenir de solution numérique directe.\n\nRemarque: les équations de score sont utilisées pour tester la validité de l’hypothèse de constance des rapports de risque pour calculer les résidus de Schoenfeld (voir plus loin).\n\nConditions de second ordre: calcul des dérivées secondes qui permettent d’obtenir la matrice d’information de Fisher et la matrice des variances-covariances des paramètres.\nComme il n’y a pas de solution numérique directe, on utilise un algorithme d’optimisation (ex: Newton-Raphson) à partir des équations de score et de la matrice d’information de Fisher.\n\nEléments de calcul\nEn logarithme (sans évènement simultané), la vraisemblance partielle s’ecrit:\n\\[pl(b)=\\sum_{i=1}^n\\delta_i\\left(log(e^{X_{i}^{'}b})-log\\sum_{j\\in R_i}e^{X_{j}^{'}b}\\right)\\]\n\\[pl(b)=\\sum_{i=1}^n\\delta_i\\left(X_{i}^{'}b-log\\sum_{j\\in R_i}e^{X_{j}^{'}b}\\right)\\]\nCalcul de l’équation de score pour une covariable \\(X_k\\):\n\\[\\frac{\\partial pl(b)}{\\partial{b_k}}=\\sum_{i=1}^n\\delta_i\\left(X_{ik}-\\sum_{j\\in R_i}X_{jk}\\frac{e^{X_{j}^{'}b}}{\\sum_{j\\in R_i}e^{X_{j}^{'}b}}\\right)\\]\nComme \\(\\frac{e^{X_{j}b}}{\\sum_{j\\in R}e^{X_{j}b}}\\) est une probabilité, et \\(\\sum_{j\\in R}X_{ik}\\times p_i\\) est l’espérance (la moyenne) \\(E(X_k)\\) d’avoir la caractéristique \\(X_k\\) lorsqu’un évènement a été observé. Au final:\n\\[\\frac{\\partial lp(b)}{\\partial{b_k}}= \\sum_{i=1}^n\\delta_i\\left(X_{ik} - E(X_{j\\in R_i,k}) \\right)\\]\nCette expression va permettre d’analyser le respect ou non de l’hypothèse de risques proportionnels via les résidus de Schoenfeld.\n\n\n7.1.3 Lecture des résultats\nComme il s’agit d’un modèle à risque proportionnel, les rapports de risques sont constants pendant toute la période d’observation. Il s’agit d’une propriété de l’estimation.\nCovariable binaire (indicatrice) \\(X=(0,1)\\): \\(RR=\\frac{h(t\\ |\\ X=1)}{h(t\\ |\\ X=0)}=e^b\\).\nA chaque moment de la durée \\(t\\), le risque d’observer l’évènement est \\(e^b\\) fois plus important/plus faible pour \\(X=1\\) que pour \\(X=0\\).\nCovariable quantitative (fixe dans le temps)\n\\(RR=\\frac{h(t\\ |\\ X=a+c)}{h(t\\ |\\ X=a)}=e^{c \\times{b}}\\). On prendra pour illustrer une variable type âge au début de l’exposition au risque (a) et un delta de comparaison avec un âge inférieur c.\nSi \\(c=1\\) (résultat de l’estimation): A un âge donnée, le risque de connaitre l’évènement est \\(e^b\\) fois inférieur/supérieur à celui d’une personne qui a un an de moins.\nExemple pour les insuffisances cardiaques\n\nCorrection de la vraisemblance: méthode d’Efron\nNombre d’observations: 103\nNombre de décès: 75\nLog-Vraisemblance: -289.30639\n\n\nCox: log Hazard Ratio (Risks Ratio)\n\n\nVariables\nlogRR\nStd.Err\nz\n\\(P&gt;|z|\\)\n95% IC\n\n\n\n\nyear\n-0.119\n0.0673\n-1.78\n0.076\n-0.2516;+0.0124\n\n\nage\n+0.0296\n0.0135\n2.19\n0.029\n+0.0031;+0.0561\n\n\nsurgery\n-0.9873\n0.4363\n-2.26\n0.024\n-1.8424;-0.1323\n\n\n\n\nCox: Hazard Ratio (Risks Ratio)\n\n\nVariables\nRR\nStd.Err\nz\n\\(P&gt;|z|\\)\n95%CI\n\n\n\n\nyear\n0.8872\n0.0597\n-1.78\n0.076\n0.7775; 1.0124\n\n\nage\n1.0300\n0.0139\n2.19\n0.029\n1.0031; 1.0577\n\n\nsurgery\n0.3726\n0.1625\n-2.26\n0.024\n0.1584; 0.8761\n\n\n\nOn retrouve les des tests non paramétriques pour l’opération, à savoir qu’un pontage réduit les risques journaliers de décès pendant la période d’observation (augmente la durée de survie).\nDe la même manière, plus on entre à un âge élevé dans la liste d’attente plus le risque de décès augmente. La variable year, qui traduit des progrès en médecine, renvoie à une réduction plutôt modérée du risque journalier de décès durant l’attente d’une greffe.\nR-Stata-Sas-Python\n\nRStataSASPython\n\n\nLe modèle est estimé avec la fonction coxph de la librairie survival. Hors options, la syntaxe est identiques aux fonctions survfit et survdif.\n\n\nLe modèle est estimé avec la commande stcox.\n\n\nLe modèle est estimé avec la proc phreg.\n\n\nAvec la librairie lifelines, le modèle est estimé avec la fonction CoxPHFitter. Avec la librairie statmodels, il est estimé avec la fonction smf.phreg."
  },
  {
    "objectID": "07-cox.html#analyse-de-la-constance-des-rapports-de-risque",
    "href": "07-cox.html#analyse-de-la-constance-des-rapports-de-risque",
    "title": "7  Le modèle de Cox",
    "section": "7.2 Analyse de la constance des rapports de risque",
    "text": "7.2 Analyse de la constance des rapports de risque\n\nLes rapports de risque (RR) estimés par le modèle sont contraints à être constant sur toute la période d’observation. C’est une hypothèse forte.\nLe respect de cette hypothèse doit être analysé, en particulier pour le modèle de Cox où la baseline du risque est habituellement estimée à l’aide de ces rapports (par exemple la méthode dite de Breslow, non traitée). En post-estimation, les valeurs estimées du risque pourront présenter des valeurs aberrantes si on dévie trop de constance, en particulier en obtenant des négatives des taux de risque.\nAnalyser cette hypothèse revient à introduire une interaction entre les rapports et la durée ou plutôt précisément une fonction de la durée).\nPlusieurs méthodes disponibles, on traitera celles basées sur les résidus de Schoenfeld, et l’introduction directe d’une intéraction entre une fonction la durée et les covariables du modèle. Cette dernière fait également office de méthode de correction lorsque la violation de l’hypothèse est jugée trop importante ou problématique du point de vue des résultats obtenus.\nSi on regarde les courbes de Kaplan-Meier, leurs croisement non tardif impliquera nécessairement un problème sur cette hypothèse.\n\n\n7.2.1 Test de Grambsch-Therneau sur les résidus de Schoenfeld\nCe test a été proposé par P.Grambsch et T.Therneau 3 dans un cadre à durée strictement continue. Il repose originellement sur une régression linéaire estimé avec les moindres carrés généralisés (GLS) correction de l’autocorrélation des erreurs avec des sér) . Dans un premier temps pour des raisons plutôt pratiques (informatique), le test a une version moindres carrés ordinaires (OLS). Jusqu’en 2020, tous les logiciels ne proposaient que le test OLS. T.Therneau avec la V3 de package survival a substitué - assez brutalement - le test GLS au test OLS. Si les résultats sont proches dans le cadre d’une durée continue et que le test GLS peut être considéré comme un test exact, cela devient problématique dans une situation de durée discrète/groupée 4. Le test OLS reste, à mon sens, la méthode à privilégier dans le cas discret.\nIl est également important de souligner que pour P.Grambsch et T.Therneau 5 n’est qu’un moyen parmi d’autres d’analyser une violation de l’hypothèse de proportionnalité. Ce n’est pas the solution (comme tout autre test au passage). Le croisement des courbes de séjours peut-être suffisant pour alerter sur cette violation.\nPrincipe du test: consiste à regarder la corrélation entre les résidus de Schoenfeld obtenus directement avec la fonction de score de la vraisemblanc partielle de Cox et une fonction de la durée.\nPrincipe de calcul des résidus\n\nLes résidus bruts sont directement calculés à partir des équations de scores [voir section estimation].\nIls ne sont calculés que pour les observations qui ont connues l’évènement, au moment où un évènement s’est produit.\nLa somme des résidus pour chaque covariable est égale à 0. Il s’agit de la propriété de l’équation de score à l’équilibre.\nOn utilise généralement les résidus standardisés (remis à l’échelle / scaled) - par leur variance -. C’est la mesure de cette variance qui distingue le test OLS du test GLS.\n\nPour une observation dont l’évènement s’est produit en \\(t_i\\), le résidu brut de Schoenfeld pour la covariable \\(X_k\\), après estimation du modèle, est égal à:\n\\[rs_{ik}=X_{ik}- \\sum_{j\\in R_i}X_{jk}\\frac{e^{X_{j}^{'}b}}{\\sum_{j\\in R_i}e^{X_{j}^{'}b}}= X_{ik} - E(X_{j\\in R_i})\\]\n\nCe résidu est formellement la contribution d’une observation ou d’un moment d’évènement au score. Il se lit comme la différence entre la valeur observée d’une covariable et sa valeur espérée au moment où l’évènement s’est produit.\nSi la constance des rapports de risque varie peu les résidus ne doivent pas suivre une tendance précise localement ou globalement, à la hausse ou à la baisse.\n\nPourquoi?\nPar l’exemple, sans censure à droite et en ne considérant que les résidus bruts: Avec un rapport de risque strictement égal à 1 en début d’exposition, une population soumise au risque \\(R_i=100\\) avec 50 hommes et 50 femmes. Si l’hypothèse PH (strictement) respectée, lorsqu’il reste 90 personnes soumises au risque, on devrait avoir 45 hommes et 45 femmes. Avec \\(R_i=50\\), 25 hommes et 25 femmes,…….avec \\(R_i=10\\), 5 hommes et 5 femmes.\nAu final l’espérance d’avoir la caractéristique \\(X\\) est toujours égal à 0.5 et les résidus bruts prendront toujours la valeur -.5 si \\(X=0\\) et .5 si \\(X=1\\). En faisant une simple régression linéaire entre les résidus, qui alternent ces deux valeurs, et \\(t\\), le coefficient estimé sera en toute logique très proche de 0.\nDe manière encore plus simple, cette proportionnalité avec un risque ratio égal à 1 suggère qu’au cours de la durée d’observation, on observe une succession d’un même nombre d’hommes et de femmes qui connaissent l’évènement. Si tous les hommes ou presque avaient observés l’évènement plutôt en début d’éxposition et si toutes les femmes ou presque avaient observé l’évènement plutôt en fin d’exposition, l’hypothèse de proportionnalité pourraient fortement remise en cause.\nOn trouvera des éléments de calcul du test OLS ici\n\n\n\n\n\n\nAvertissement\n\n\n\n\nTest omnibus: Ne pas l’utiliser bien qu’il figure généralement en bas des output. Il n’a pas d’interprétation directe, et les p-value peuvent présenter des valeurs très faibles alors que ce n’est pas le cas pour les covariables prises une à une. Rester comme c’est souvent le cas à un test à un degré de liberté.\nTransformations de la durée: n’importe quelle fonction de la durée peut être utilisée pour réaliser le test. On retient généralement les fonctions suivantes: \\(g(t)=t\\) (« identity »), \\(g(t)=log(t)\\), \\(g(t)=KM(t)\\) ou \\(g(t)=1- S(t\\)) où \\(S(t\\)) est l’estimateur de Kaplan-Meier. Enfin une transformation appelée « rank » est utilisée seulement pour les durées strictement continue ou suffisamment dispersées . Par exemple \\(t=(0.1,0.5,1,2.6,3)\\) donne une transformation \\(t=(1,2,3,4)\\). A savoir : $g(t)=t rend le test relativement sensible aux évènements tardifs lorsque la population restant soumise est peu nombreuse (outliers).\nPar défaut Stata, Sas, Python: \\(g(t)=t\\)\nPar défaut R: \\(g(t)= 1 - S(t)\\)\n\n\n\nPour des raisons de reproductibilité dans l’espace des logiciels et dans le temps pour les différentes versions du package survival de R, on ne présente ici que la version OLS.\nTest OLS avec \\(g(t)=t\\)\n\nTest OLS Grambsch-Therneau avec \\(g(t)=t\\)\n\n\nVariables\nchi2\ndf\nP&gt;Chi2\n\n\n\n\nyear\n0.80\n1\n0.3720\n\n\nage\n1.61\n1\n0.2043\n\n\nsurgery\n5.54\n1\n0.0186\n\n\n\nIci l’hypothèse de proportionnalité des risques est questionnable pour la variable surgery. Le risque ratio pourrait ne pas constant dans le temps. Ce n’est pas du tout étonnant, le premier décès pour les personnes opérées d’un pontage n’est observé qu’au bout de 165 jours. Au final, un test était-il bien nécessaire pour arriver à ce constat ???????\nTest OLS avec \\(g(t)=1- S(t)\\)\n\nTest Grambsch-Therneau avec \\(g(t)=1- S(t)\\)\n\n\nVariables\nchi2\ndf\nP&gt;Chi2\n\n\n\n\nyear\n1.96\n1\n0.162\n\n\nage\n1.15\n1\n0.284\n\n\nsurgery\n3.96\n1\n0.046\n\n\n\nR-Stata-Sas-Python\n\nRStataSASPython\n\n\nAttention seulement version GLS du test depuis le V3 de survival.\n\nAprès avoir créer un objet à l’estimation du modèle de Cox, on utilise la fonction cox.zph. Cette fonction utilise par défaut \\(g(t)=1-S(t)\\) où \\(S(t)\\) sont les estimateurs de la courbe de Kaplan-Meier. On peut modifier cette fonction. Il est préférable de conserver cette fonction par défaut.\nTest OLS: j’ai récupéré le programme du test antérieur, renommé cox.zphold. On peut le charger simplement, et il est facilement exécutable. Pour le charger: source(\"https://raw.githubusercontent.com/mthevenin/analyse_duree/main/cox.zphold/cox.zphold.R\")\n\n\n\nLe test (OLS) est obtenu avec la commande estat phtest, d. Par défaut Stata utilise \\(g(t)=t\\). On peut modifier cette fonction.\n\n\nLe test (OLS) est disponible depuis quelques années avec l’argument zph sur la ligne proc lifetest. Par défaut SAS utilise \\(g(t)=t\\). On peut modifier cette fonction.\n\n\nLe test (OLS) est donné avec la fonction proportional_hazard_test de la librairie lifelines. La fonction utilise par défaut \\(g(t)=t\\), mais on peut afficher les résultats pour toutes les transformations de \\(t\\) disponibles avec l’option time_transform=’all’.\n\n\n\n\n\n7.2.2 Intéraction avec la durée\nPetit retour sur l’estimation du modèle\nPour estimer le modèle de Cox, les données sont dans un premier temps splitées aux moment où au moins un évènement a été observé.\nSur l’application, avec 2 individus avec la covariable age (rappel: il s’agit de l’âge en \\(t_0\\):\n\nBase spittées sur les intervals d’évènement\n\n\nid\nage\ndied\n\\(t_0\\)\n\\(t\\)\n\n\n\n\n2\n51\n0\n0\n1\n\n\n2\n51\n0\n1\n2\n\n\n2\n51\n0\n2\n3\n\n\n2\n51\n0\n3\n5\n\n\n2\n51\n1\n5\n6\n\n\n3\n54\n0\n0\n1\n\n\n3\n54\n0\n1\n2\n\n\n3\n54\n0\n2\n3\n\n\n3\n54\n0\n3\n5\n\n\n3\n54\n0\n5\n6\n\n\n3\n54\n0\n6\n8\n\n\n3\n54\n0\n8\n9\n\n\n3\n54\n0\n9\n12\n\n\n3\n54\n1\n12\n16\n\n\n\nLes bornes des intervalles \\([t_0;t]\\) présentent des valeurs seulement lorsqu’un évènement s’est produit (principe de la vraisemblance partielle). Il n’y a donc pas de valeurs pour \\(t\\) et \\(t_0\\) en \\(t=4\\) pour \\(id=(2,3)\\)et \\(t=7,10,11,13,14,15\\) pour \\(id=3\\).\nLes deux individus observent l’évènement en \\(t=6\\) pour \\(id=2\\), et en \\(t=16\\) pour \\(id=3\\). Avant ce moment la valeur de la variable évènement/censure (ici \\(d\\)) prend toujours la valeur 0, et prend la valeur 1 le jour du décès.\nSur cette base splitée aux moments d’évènement (n=3573), on pourra vérifier facilement que les résultats obtenus par le modèle de Cox sont identiques à ceux obtenus précédemment.\nIntroduction d’une intéraction avec une fonction de la durée\nOn a une variable de durée (on prendra \\(g(t)=t\\)) qui sera croisée avec la variable surgery.\nLe modèle s’écrit:\n\\[h(t | X,t) = h_0(t)e^{b_1age + b_2year + b_3 surgery + b_4 (surgery\\times t)}\\]\nLe modèle avec cette intéraction donne les résultats suivants:\n\nModèle de Cox avec une intéraction entre une fonction de la durée et la variable *surgery\n\n\n\n\n\n\n\n\n\n\nVariable\n\\(e^b\\)\nStd.err\nz\nP&gt;|z|\n95% IC\n\n\n\n\nyear\n0.884\n0.059\n-1.84\n0.066\n0.776 ; 1.008\n\n\nage\n1.029\n0.014\n+2.15\n0.032\n1.003 ; 1.057\n\n\n\\(surgery(t_{0+})\\)\n0.173\n0.117\n-2.60\n0.009\n0.046 ; 0.649\n\n\n\\(surgery\\times t\\)\n1.002\n0.001\n+2.02\n0.043\n1.000 ; 1.004\n\n\n\nOn retrouve donc un résultat proche de celui obtenu à partir du test OLS sur les résidus de Schoenfeld pour la variable surgery. Et c’est normal. Avec \\(g(t)=t\\), il a le mérite de pouvoir être interprété directement. Ce qui ne veut pas dire qu’il s’agit de la meilleure solution.\nDonc, malgré une hypothèse plutôt forte sur la forme fonctionnelle de l’intéraction, et dans les faits surement pas pertinente, on peut dire que chaque jour le rapport des risques entre personnes opérées et personnes non opérées augmente de +0.2%. Pour plus précis, étant à l’origine &lt;1, l’écart se modère. L’effet de l’opération sur la survie des individus s’estompe donc avec le temps.\nA noter\n\nLe modèle n’est plus un modèle à risque proportionnel. La variable surgery n’est plus une variable fixe mais une variable tronquée dynamique qui prend la valeur de \\(t\\) pour les personnes qui ont été opérées d’un pontage avant leur entrée dans le registre de greffe.\n\nSi \\(surgery = 0\\)\n\n\n\nid\nsurgery\ndied\n\\(t_0\\)\n\\(t\\)\nsurgery*t\n\n\n\n\n2\n0\n0\n0\n1\n0\n\n\n2\n0\n0\n1\n2\n0\n\n\n2\n0\n0\n2\n3\n0\n\n\n2\n0\n0\n3\n5\n0\n\n\n2\n0\n1\n5\n6\n0\n\n\n\nSi \\(surgery = 1\\) (jusqu’à \\(t=6\\) car aucun décès précoce pour ce groupe)\n\n\n\nid\nsurgery\ndied\n\\(t_0\\)\n\\(t\\)\nsurgery*t\n\n\n\n\n40\n1\n0\n0\n1\n1\n\n\n40\n1\n0\n1\n2\n2\n\n\n40\n1\n0\n2\n3\n3\n\n\n40\n1\n0\n3\n5\n5\n\n\n40\n1\n1\n5\n6\n6\n\n\n\nExemple pour une variable quantitative (age)\n\n\n\nid\nage\ndied\n\\(t_0\\)\n\\(t\\)\nage*t\n\n\n\n\n2\n51\n0\n0\n1\n51\n\n\n2\n51\n0\n1\n2\n102\n\n\n2\n51\n0\n2\n3\n153\n\n\n2\n51\n0\n3\n5\n255\n\n\n2\n51\n1\n5\n6\n306\n\n\n\n\nL’altération des rapports de risque dépend de la forme fonctionnelle de l’intéraction choisie. Ici la variation dans la durée du rapport des risque est constante, ce qui est une hypothèse assez forte. On a, en quelques sorte, réintroduit une hypothèse de proportionnalité, ici sur le degré d’altération des écarts de risques dans le temps, qui devient lui même strictement constant.\n\n\n\n7.2.3 Que faire ?\nNe rien faire\nOn interprète le risque ratio comme un ratio moyen pendant la durée d’observation (P.Allison). Difficilement soutenable pour l’analyse des effets cliniques, elle peut être envisagée dans d’autres domaines. Attention au nombre de variables qui ne respectent pas l’hypothèse, l’estimation de la baseline du risque pourrait être sensiblement affectée si l’analyse a des visée prédictives. Il convient tout de même lors de l’interprétation, de préciser les variables qui seront analysées sous cette forme très « moyenne » sur la période d’observation.\nOn peut également adapter cette stratégie du « ne rien faire » selon sens de l’altération des rapports de risque. Si aux cours du temps des écarts de risque, s’accentuent à la hausse comme à la baisse, on peut conserver cet estimateur moyen. Mais si cette non proportionnalité conduit à un changement du sens des rapport de risque je suis moins convaincu de la pertinence de cette stratégie. Encore une fois, et il faut le rappeler, l’estimation des courbes de survie doit permette d’anticiper ce dernier cas de figure.\nIl faut également tenir compte de l’intérêt portée par les variables qui présentent un problème par rapport à l’hypothèse. Il n’est peut-être pas nécessaire de complexifier le modèle pour des variables introduites comme simples contrôles.\nMais plus problématique [important]… On sait qu’une des causes du non respect de l’hypothèse peut provenir d’effets de sélection liées à des variables omises ou non observables. En analyse de durée ce problème prend le nom de frailty (fragilité) lorsque cette non homogénéité n’est pas observable. Des estimations, plus complexes, sont possibles dans ce cas, et sont en mesure malgré leur interprétation plutôt difficile de régler le problème. Il convient donc de bien spécifier le modèle au niveau des variables de contrôle observables et disponibles.\nModèle de Cox stratifié\nUtiliser la méthode dite de « Cox stratifiée » (non traitée). Utile si l’objectif est de présenter des fonctions de survie prédites ajustées, et si une seule covariable (binaire) présente un problème. Les HR ne seront pas estimés pour la variable qui ne respecte pas l’hypothèse.\nIntéraction\nIntroduire une interaction avec la durée. Cela peut permettre en plus d’enrichir le modèle au niveau de l’interprétation. Valable si peu de covariables présentent des problèmes de stabilité des rapports de risque, dans l’idéal une seule variable. Attention tout de même à la forme de la fonction, dans l’exemple on a contraint l’effet d’interaction à être strictement linéaire, ce qui est une hypothèse plutôt forte…. on introduit de nouveau une contrainte de proportionnalité dans le modèle.\nModèles alternatifs\nUtiliser un modèle alternatif: modèles paramétriques à risques proportionnels si la distribution du risque s’ajuste bien, le modèle paramétrique « flexible » de Parmar-Royston ou un modèle à temps discret. Pour la dernière solution, on peut également corriger la non proportionnalité avec l’introduction d’une intéraction. Si on ne le fait pas, les risques prédits, par définition des probabilités conditionnelles, resteront toujours dans les bornes contrairement au modèle de Cox.\nUtiliser un modèle non paramétrique additif dit d’Aalen ou une de ses variantes (non traité). Mais ces modèles, dont les résultats sont présentés par des graphiques, se commentent assez difficilement.\nForêt aléatoire\nAutre méthode : les forêts aléatoires. L.Breiman a dès le départ proposé une estimation des modèles de survie par cette méthode. Par définition, pas sensible à l’hypothèse PH. Mais cela reste des méthodes à finalité prédictive, moins riche en interprétation."
  },
  {
    "objectID": "07-cox.html#footnotes",
    "href": "07-cox.html#footnotes",
    "title": "7  Le modèle de Cox",
    "section": "",
    "text": "Se reporter à la définition des grandeurs dans la section Théorie↩︎\n\\(n! = (n)\\times(n-1)\\times(n-2)\\times....\\times3\\times2\\times1\\)↩︎\nIl s’agit bien de la personne qui maintient le package survival dans R↩︎\nPour les personnes utilisant R, je donne un moyen pour récupérer et exécuter le test OLS sous R↩︎\nSe reporter à leur ouvrage Modeling Survival Data: Extending the Cox Model (2001)↩︎"
  },
  {
    "objectID": "08-discret.html#organisation-des-données",
    "href": "08-discret.html#organisation-des-données",
    "title": "8  Modèle à durée discrète",
    "section": "8.1 Organisation des données",
    "text": "8.1 Organisation des données\nFormat long\nLes données doivent être en format long: pour chaque individu on a une ligne par durée observée ou par intevalle de durées jusqu’à l’évènement ou la censure. On retrouve le split des données du modèle de Cox, mais généralisé à des intervalles où aucun évènement n’est observé. Avec des données de type discrètes ou groupées, phénomène classique en sciences sociales, il y a souvent peu de différence entre un allongement aux temps d’évènement et aux temps d’observation.\n\nDurée\nLa durée est dans un premier temps construite sous forme d’un simple compteur, par exemple \\(t=1,2,3,4,5...\\) (des valeurs non entières sont possibles). Le choix de la forme fonctionnelle de la durée sera présentée plus tard.\nVariable évènement/censure\nSi l’individu a connu l’évènement, elle prend la valeur 0 avant celui-ci. Au moment de l’évènement sa valeur est égale à 1. Pour les observations censurées, la variable prend toujours la valeur 0.\nApplication\nOn reprend les données de la base transplantation, mais les durées ont été regroupées par période de 30 jours. Il n’y a pas de durée mesurée comme nulle, on a considéré que les 30 premiers jours représentaient, le premier mois d’exposition. Cette variable de durée se nomme mois.\nFormat d’origine\n\nDurée discrète: données en format d’origine\n\n\nid\nyear\nage\nsurgery\nmois\ndied\n\n\n\n\n1\n67\n30\n0\n2\n1\n\n\n\nLa personne décède lors du deuxième intervalle de 30 jours\nFormat long et variables pour l’analyse\n\nDurée discrète: données en format long\n\n\nid\nyear\nage\nsurgery\nmois\ndied\nt\n\n\n\n\n1\n67\n30\n0\n2\n0\n1\n\n\n1\n67\n30\n0\n2\n1\n2"
  },
  {
    "objectID": "08-discret.html#ajustement-de-la-durée",
    "href": "08-discret.html#ajustement-de-la-durée",
    "title": "8  Modèle à durée discrète",
    "section": "8.2 Ajustement de la durée",
    "text": "8.2 Ajustement de la durée\nUn des principaux enjeux réside dans la paramétrisation de la durée:\n\nElle peut-être modélisée sous forme de fonction d’une variable de type quantitative/continue.\nElle peut-être modélisée comme variable discrète, de type indicatrice \\({0;1}\\), sur tous les points d’observation, ou sous forme de regroupements. Il doit y avoir au moins un évènement observé dans chaque intervalle.\n\n\n8.2.1 Ajustement avec une durée en continu\nLe modèle étant paramétrique, on doit trouver une fonction qui ajuste le mieux les données. Toutes transformations de la variable est possible: \\(f(t)=a\\times t\\), \\(f(t)=a\\times ln(t)\\)……formes quadratiques. Les ajustements sous forme de splines (cubiques) tendent à se développer ces dernières années.\nPour sélectionner cette fonction, on peut tester différents modèles sans covariable additionnelle, et sélectionner la forme dont le critère d’information de type AIC (vraisemblance pénalisée) est le plus faible.\nExemple:\nOn va tester les paramétrisations suivante:s une forme linéraire stricte \\(f(t)=a\\times t\\) et des effets quadratiques d’ordres 2 et 3: \\(f(t)=a_1\\times t + a_2\\times t^{2}\\) et \\(f(t)=a_1\\times t + a_2\\times t^{2} + a_3\\times t^{3}\\).\n\n\n\nProbabilité de décéder avec 3 ajustements de la durée\n\n\nCritères AIC\n\n\n\n\\(f(t)\\)\nAIC\n\n\n\n\n\\(a\\times t\\)\n504\n\n\n\\(a_1\\times t + a_2\\times t^{2}\\)\n492\n\n\n\\(a_1\\times t + a_2\\times t^{2} + a_3\\times t^{3}\\)\n486\n\n\n\nOn peut utiliser la troisième forme à savoir \\(a_1\\times t + a_2\\times t^{2} + a_3\\times t^{3}\\).\nEstimation du modèle avec toutes les covariables\n\nModèle logistique à durée discrète (\\(f(t)\\) continue)\n\n\n\n\n\n\n\n\n\n\nVariables\nOR - RR\nStd. err\nz\nP&gt;|z|\n95% IC\n\n\n\n\n\\(t\\)\n0.678\n0.057\n-4.52\n0.000\n0.587 ; 0.810\n\n\n\\(t^2\\)\n1.014\n0.005\n+2.83\n0.005\n1.004 ; 1.024\n\n\n\\(t^3\\)\n1.000\n0.000\n-2.11\n0.035\n1.000 ; 1.000\n\n\n\\(year\\)\n0.876\n0.015\n-1.80\n0.072\n0.758 ; 1.012\n\n\n\\(age\\)\n1.034\n0.163\n+2.27\n0.023\n1.005 ; 1.064\n\n\n\\(surgery\\)\n0.364\n0.110\n-2.25\n0.024\n0.151 ; 0.877\n\n\n\n\n\n\n\n\n\n\nConstante\n0.440\n0.110\n-3.29\n0.001\n0.270 ; 0.718\n\n\n\nRemarque: les variables year et age ont été centrée sur leur moyenne pour rendre la constante interprétable. La constante reporte donc l’Odds de décéder lors des 30 premiers jours d’une personne dont l’âge et l’année à l’entrée dans le registre est égal à l’âge et à l’année moyenne et qui n’a pas été opéré préalablement.\nSi maintenant on estime un modèle de Cox sur ces données journalières groupées, on remarque que les résultats obtenus sont très proches\n\nModèle de Cox\n\n\n\n\n\n\n\n\n\n\nVariables\nOR - RR\nStd. err\nz\nP&gt;|z|\n95% IC\n\n\n\n\n\\(year\\)\n0.878\n0.059\n-1.93\n0.053\n0.769 ; 1.002\n\n\n\\(age\\)\n1.029\n0.014\n+2.13\n0.033\n1.002 ; 1.057\n\n\n\\(surgery\\)\n0.379\n0.165\n-2.22\n0.026\n0.111 ; 0.892\n\n\n\n\n\n8.2.2 Ajustement discret\n\nIl s’agit d’introduire la variable de durée dans le modèle comme une variable catégorielle (indicatrices).\nDémarche pas conseillé si on a beaucoup de points d’observation, ce qui est le cas ici.\nA l’inverse, si peu de points d’observation la paramétrisation avec une durée continue n’est pas conseillé.\nLa correction de la non proportionnalité peut être plus compliquée à mettre en oeuvre.\n\nOn va supposer que l’on ne dispose que de 4 intervalles d’observation. Pour l’exemple, on va créer ces points à partir des quartiles de la durée, et conserver pour chaque personne une seule observation par intervalle.\n\n\\(t=1\\): Entre le début de l’exposition et 4 mois.\n\\(t=2\\): Entre 5 mois et 11 mois .\n\\(t=3\\): Entre 12 mois et 23 mois.\n\\(t=4\\): 24 mois et plus.\n\nOn va estimer le risque globalement sur l’intervalle. La base sera plus courte que la précédente (197 observations pour 103 individus). Il ne sera plus possible ici d’interpréter les résultats en termes de rapport de probabilité, l’évènement devenant trop fréquent à l’intérieur de chaque intervalle.\n\nModèle logistique à durée discrète (\\(f(t)\\) indicatrices)\n\n\n\n\n\n\n\n\n\n\nVariables\nOR - RR\nStd. err\nz\nP&gt;|z|\n95% IC\n\n\n\n\n\\(0-4 mois\\)\n2.811\n1.177\n+2.47\n0.014\n1.237 ; 6.387\n\n\n\\(5-11 mois\\)\nref\n-\n-\n-\n-\n\n\n\\(12-23 mois\\)\n0.559\n0.346\n-0.94\n0.347\n0.166 ; 1.881\n\n\n\\(24-46 mois\\)\n1.741\n1.159\n+0.83\n0.405\n0.472 ; 6.417\n\n\n\\(year\\)\n0.816\n0.076\n-2.18\n0.029\n0.680 ; 0.980\n\n\n\\(age\\)\n1.048\n0.019\n+2.53\n0.011\n1.011 ; 1.087\n\n\n\\(surgery\\)\n0.330\n0.166\n-2.21\n0.027\n0.123 ; 0.882\n\n\n\n\n\n\n\n\n\n\nConstante\n0.407\n0.151\n2.43\n0.015\n0.198 ; 0.840\n\n\n\nOn trouve des résultats proches de ceux éstimés avec un ajustement continu de la durée. C’est normal, la dirée fait office de variable d’ajustement peu ou pas corrélée avec les autres variables introduites.\n\n\n\nVariables\nAjustement discret\nAjustement continu\n\n\n\n\n\\(year\\)\n0.816\n0.876\n\n\n\\(age\\)\n1.048\n1.034\n\n\n\\(surgery\\)\n0.330\n0.364"
  },
  {
    "objectID": "08-discret.html#proportionnalité-des-risques",
    "href": "08-discret.html#proportionnalité-des-risques",
    "title": "8  Modèle à durée discrète",
    "section": "8.3 Proportionnalité des risques",
    "text": "8.3 Proportionnalité des risques\n\nFormellement un modèle logistique à temps discret repose sur une hypothèse d’Odds proportionnel [Odds ratios constants pendant la durée d’observation]. Contrairement au modèle de Cox, l’estimation des probabilités (risque) n’est pas biaisée si l’hypothèse PH n’est pas respectée, les paramètres estimés sont considérés au pire comme des approximation.\nComme pour le modèle de Cox, la correction de la non proportionnalité peut se faire en intégrant une interaction avec la durée dans le modèle.\n\nAvec un ajustement continue, on remarque de nouveau que le résultat du modèle est de nouveau très proche de celui estimé avec un modèle de Cox.\n\nModèle logistique à durée discrète avec correction de la non proportionnalité\n\n\n\n\n\n\n\n\n\n\nVariables\nOR - RR\nStd. err\nz\nP&gt;|z|\n95% CI\n\n\n\n\n\\(t\\)\n0.702\n0.059\n-4.2\n0.000\n0.595 ; 0.828\n\n\n\\(surgery(t=0)\\)\n0.155\n0.108\n-2.67\n0.008\n0.039 ; 0.609\n\n\n\\(surgery\\times t\\)\n1.072\n0.036\n2.08\n0.037\n1.004 ; 1.145\n\n\n\\(t^2\\)\n1.013\n0.005\n2.37\n0.018\n1.002 ; 1.023\n\n\n\\(t^3\\)\n1.00\n0.000\n-1.71\n0.086\n1.000 ; 1.000\n\n\n\\(year\\)\n0.872\n0.064\n-1.86\n0.062\n0.755 ; 1.007\n\n\n\\(age\\)\n1.033\n0.015\n2.23\n0.026\n1.004 ; 1.063\n\n\n\\(constante\\)\n0.445\n0.112\n-3.22\n0.001\n0.272 ; 0.728\n\n\n\nSi on avait omis les variables year et age du modèle:\n\n\n\nProbabilité de décéder après correction de la non proportionnalité pour la variable surgery"
  },
  {
    "objectID": "09-tvc.html#facteur-dynamique-traitée-de-manière-fixe",
    "href": "09-tvc.html#facteur-dynamique-traitée-de-manière-fixe",
    "title": "9  Variables dynamiques",
    "section": "9.1 Facteur dynamique traitée de manière fixe",
    "text": "9.1 Facteur dynamique traitée de manière fixe\nOn reprend l’exemple sur malformation cardiaque, en ajoutant la variable relative à la greffe. La question est donc de savoir si une transplantation du coeur réduitle risque journalier de décéder (ou augmente la durée de survie).\nOn a dans la base 2 variables: une variable binaire pour savoir si l’individu à été greffé ou non, transplant, et la variable wait de type continue tronquée donnant la durée en jour jusqu’à l’opération depuis l’inscription dans le registre (0 si \\(transplant=0\\)).\nOn va dans un premier temps estimer le modèle de Cox avec la variable fixe transplant.\n\nModèle de cox avec une variable dynamique (binaire) traitée de manière fixe (estimation biaisée\n\n\nVariables\nHR\nStd. err\nz\nP&gt;|z|\n95% CI\n\n\n\n\nyear\n0.910\n0.060\n-1.42\n0.155\n0.799 ; 1.036\n\n\nage\n1.054\n0.015\n3.71\n0.000\n1.025 ; 1.084\n\n\nsurgery\n0.541\n0.243\n-1.37\n0.171\n0.224 ; 1.304\n\n\ntransplant\n0.278\n0.088\n-4.06\n0.000\n0.150 ; 0.515\n\n\nwait\n0.992\n0.005\n-1.50\n0.134\n0.982 ; 1.002\n\n\n\nInterprétation: traitée de manière fixe, la greffe réduit donc sensiblement le risque journalier de décéder (RR=0.278). De même on peut admettre une certaine cohérence pour la durée jusqu’à la transplantation: plus elle est précoce et plus les personnes survivent (HR=0.992).\nSauf que…..\nAu niveau des données le modèle à été estimé, pour une personne greffée (ici id=70), à partir de ce mapping:\n\nMapping de la base avec une variable dynamique binaire traitée de manière fixe\n\n\nid\nyear\nage\nsurgery\ntransplant\nwait\ndied\n\\(t_0\\)\n\\(t\\)\n\n\n\n\n70\n72\n52\n0\n1\n5\n0\n0\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n1\n2\n\n\n70\n72\n52\n0\n1\n5\n0\n2\n3\n\n\n70\n72\n52\n0\n1\n5\n0\n3\n5\n\n\n70\n72\n52\n0\n1\n5\n0\n5\n6\n\n\n70\n72\n52\n0\n1\n5\n0\n6\n8\n\n\n70\n72\n52\n0\n1\n5\n0\n8\n9\n\n\n70\n72\n52\n0\n1\n5\n0\n9\n12\n\n\n70\n72\n52\n0\n1\n5\n0\n12\n16\n\n\n70\n72\n52\n0\n1\n5\n0\n16\n17\n\n\n70\n72\n52\n0\n1\n5\n0\n17\n18\n\n\n70\n72\n52\n0\n1\n5\n0\n18\n21\n\n\n70\n72\n52\n0\n1\n5\n0\n21\n28\n\n\n70\n72\n52\n0\n1\n5\n1\n28\n30\n\n\n\nUne personne est codée greffée avant le jour de la transplantation. L’effet causal est donc mal mesuré si sa dimension temporelle a été ignorée, ici le jour exact de l’opération. C’est le même principe pour l’évènement, la personne est codée décédée (1) le jour du décès, et vivante avant (0)."
  },
  {
    "objectID": "09-tvc.html#estimation-avec-une-variable-dynamique",
    "href": "09-tvc.html#estimation-avec-une-variable-dynamique",
    "title": "9  Variables dynamiques",
    "section": "9.2 Estimation avec une variable dynamique",
    "text": "9.2 Estimation avec une variable dynamique\nIl convient donc de modifier l’information avec le délai d’attente jusqu’à la greffe. Le principe de construction de la variable dynamique, quelle que soit le logiciel utilisé, doit suivre la logique suivante:\n\\(tvc = transplant\\) , si \\(transplant=1\\) et \\(t&lt;wait\\) alors \\(tvc=0\\)\n\n9.2.1 Modèle de Cox\n\nMapping correct de la base avec une variable dynamique binaire\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nyear\nage\nsurgery\ntransplant\nwait\ndied\n\\(t_0\\)\n\\(t\\)\nTVC\n\n\n\n\n70\n72\n52\n0\n1\n5\n0\n0\n1\n0\n\n\n70\n72\n52\n0\n1\n5\n0\n1\n2\n0\n\n\n70\n72\n52\n0\n1\n5\n0\n2\n3\n0\n\n\n70\n72\n52\n0\n1\n5\n0\n3\n5\n0\n\n\n70\n72\n52\n0\n1\n5\n0\n5\n6\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n6\n8\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n8\n9\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n9\n12\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n12\n16\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n16\n17\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n17\n18\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n18\n21\n1\n\n\n70\n72\n52\n0\n1\n5\n0\n21\n28\n1\n\n\n70\n72\n52\n0\n1\n5\n1\n28\n30\n1\n\n\n\nSi on estime maintenant le modèle avec cette variable dynamique qui indique clairement le moment de la transition (jour de la greffe):\n\nModèle de Cox avec une variable dynamique binaire\n\n\n\n\n\n\n\n\n\n\nVariables\nHR\nStd. err\nz\nP&gt;|z|\n95% CI\n\n\n\n\n\\(year\\)\n0.887\n0.060\n-1.79\n0.074\n0.777 ; 1.012\n\n\n\\(age\\)\n1.031\n0.014\n2.19\n0.029\n1.003 ; 1.059\n\n\n\\(surgery\\)\n0.374\n0.163\n-2.25\n0.024\n0.159 ; 0.880\n\n\n\\(TVC transplantation\\)\n0.921\n0.281\n-0.27\n0.787\n0.507 ; 1.674\n\n\n\nL’impact de la greffe apparaît maintenant bien plus modéré sur la survie des individus. Cela ne signifie pas non plus que des personnes ont pu être sauvée grâce à cette opération (ou plutôt leur durée de vie augmentée), mais des complications lors de l’opération ou post-opératoire, surtout à une époque où ces techniques étaient à leurs balbutiements, ont pu également accélérer la mortalité. Il faut également garder en tête que l’état de santé des personnes est particulièrement dégradé, cette opération étant celle de la dernière chance.\nR - Stata - Sas - Python\n\nSasR - Stata, Python\n\n\nLa base n’est pas modifiée et la création de la TVC est faite en aveugle dans la procédure phreg, après l’instruction model. Ce n’est franchement pas super.\n\n\nLa base doit être transformée en format long aux temps d’évènement (survsplit avec R, stsplit avec Stata) avant la création de la variable dynamique.\n\n\n\n\n\n9.2.2 Modèle à temps discret\nMême principe pour la construction de la variable dynamique. Pour rappel l’échelle temporelle est le mois, on a créé en amont une variable qui regroupe les valeurs de la variable wait en périodes de 30 jours.\n\nModèle logistique à durée discrète avec variable dynamique binaire\n\n\n\n\n\n\n\n\n\n\nVariables\nOR - RR\nStd. err.\nz\nP&gt;|z|\n95% IC\n\n\n\n\n\\(t\\)\n0.686\n0.070\n-3.71\n0.000\n0.562 ; 0.837\n\n\n\\(t^2\\)\n1.015\n0.006\n2.53\n0.011\n1.003 ; 1.026\n\n\n\\(t^3\\)\n1.000\n0.000\n-1.97\n0.049\n1.000 ; 1.000\n\n\n\\(year\\)\n0.876\n0.065\n-1.79\n0.073\n0.758 ; 1.012\n\n\n\\(age\\)\n1.034\n0.015\n2.22\n0.027\n1.004 ; 1.064\n\n\n\\(surgery\\)\n0.363\n0.163\n-2.25\n0.024\n0.151 ; 0.876\n\n\n\\(TVC \\; greffe\\)\n1.029\n0.355\n0.08\n0.934\n0.524 ; 2.022\n\n\n\n\n\n\n\n\n\n\n\\(Constante\\)\n0.440\n0.110\n-3.29\n0.001\n0.270 ; 0.718"
  },
  {
    "objectID": "09-tvc.html#précautions",
    "href": "09-tvc.html#précautions",
    "title": "9  Variables dynamiques",
    "section": "9.3 Précautions",
    "text": "9.3 Précautions\n\nRappel: la cause doit précèder l’effet.\nLorsque l’évènement étudié n’est pas intrinsèquement de type absorbant comme le décès, la cause peut se manifester ou plutôt être observée après la survenue de l’évènement étudié. Les modèles de durée standards ne peuvent pas gérer ces situations car l’observation sort du risque après la survenue de l’évènement. Il y a d’autres techniques, par exemple de type économétrique, qui sont plus à même de traiter ce genre de situations.\nMême si la cause est bien mesurée avant l’évènement d’intérêt, un choc n’est peut-être qu’un point final d’un processus causal antérieur: une séparation est rarement un évènement ponctuel, une phase plus ou moins longue de mésentente dans le couple lui a vraisemblablement préexister. La datation du début d’un processus causal n’est donc pas toujours facile à mesurer.\n\nLogique d’adaptation: la cause identifiée est mesurée avant l’évènement étudié.\nLogique d’anticipation: la cause identifiée est mesurée après l’occurrence de l’évènement étudié. L’origine causale est bien antérieure à l’évènement, mais elle n’est pas directement observable.\n\nLorsque les variables dynamiques sont de type quantitatives/continues, le problème on doit aussi considérer avec des phénomènes d’anticipation sur les valeurs attendues de ces variables, observées postérieurement à l’évènement étudié. On peut introduire des « lags » dans le modèle pour saisir ce phénomène : par exemple \\(x_t= x_{t+1}\\). Ce décalage des durées d’occurrence peut être aussi introduite pour les variables discrètes (naissance d’un enfant par exemple)."
  }
]